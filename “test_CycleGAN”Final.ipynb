{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“test_CycleGAN”Final",
      "provenance": [],
      "collapsed_sections": [
        "8daqlgVhw29P",
        "gdUz4116xhpm"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucaslu2333/Final-Project/blob/master/%E2%80%9Ctest_CycleGAN%E2%80%9DFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VIGyIus8Vr7"
      },
      "source": [
        "Take a look at the [repository](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) for more information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atNhGsfsvsZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84676535-57e2-4a53-8f30-eec8aa61d0a3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wNjDKdQy35h"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRm-USlsHgEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f046611-9576-45fb-c438-876309a41a2a"
      },
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
            "remote: Enumerating objects: 2337, done.\u001b[K\n",
            "remote: Total 2337 (delta 0), reused 0 (delta 0), pack-reused 2337\u001b[K\n",
            "Receiving objects: 100% (2337/2337), 8.09 MiB | 23.95 MiB/s, done.\n",
            "Resolving deltas: 100% (1499/1499), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt3igws3eiVp"
      },
      "source": [
        "import os\n",
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1EySlOXwwoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99a5572e-b58b-441b-dd9f-6482b45ae018"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.8.1+cu101)\n",
            "Collecting dominate>=2.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/a8/4354f8122c39e35516a2708746d89db5e339c867abbd8e0179bccee4b7f9/dominate-2.6.0-py2.py3-none-any.whl\n",
            "Collecting visdom>=0.1.8.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (7.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (20.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading https://files.pythonhosted.org/packages/40/d5/6640ac6d1bdd20f44bb6b3c6e6f2f1c525bf0b7595f99c4f38917f995d6b/jsonpatch-1.28-py2.py3-none-any.whl\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting websocket-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 16.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2020.11.8)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-cp36-none-any.whl size=655251 sha256=6ed50fb0b5e8ea68941699f5c5ab57842da77f108ecac3a479fe7dd562c25cff\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5711 sha256=a0bf7eff11995bfe562a4eadaed6595881e87d25c98ed7a6d8e84bde5a114600\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: dominate, jsonpointer, jsonpatch, torchfile, websocket-client, visdom\n",
            "Successfully installed dominate-2.6.0 jsonpatch-1.28 jsonpointer-2.0 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8daqlgVhw29P"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "Download one of the official datasets with:\n",
        "\n",
        "-   `bash ./datasets/download_cyclegan_dataset.sh [apple2orange, orange2apple, summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrdOettJxaCc"
      },
      "source": [
        "# !bash ./datasets/download_cyclegan_dataset.sh horse2zebra"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdUz4116xhpm"
      },
      "source": [
        "# Pretrained models\n",
        "\n",
        "Download one of the official pretrained models with:\n",
        "\n",
        "-   `bash ./scripts/download_cyclegan_model.sh [apple2orange, orange2apple,summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower]`\n",
        "\n",
        "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B75UqtKhxznS"
      },
      "source": [
        "# !bash ./scripts/download_cyclegan_model.sh horse2zebra"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKYWg1tRuKNr"
      },
      "source": [
        "# If Train Your Own Model\n",
        "Skip the previous two steps but use your own dataset by creating the appropriate folders and adding in the images.\n",
        "\n",
        "-   Create a dataset folder and name it eg. `sketch2shanshui` as your dataset ad upload it to google drive and get the \"id\"\n",
        "-   Create subfolders `testA`, `testB`, `trainA`, and `trainB` under your dataset's folder. Place any images you want to transform from a to b (cat2dog, sketch2shanshui) in the `testA` folder, images you want to transform from b to a (dog2cat) in the `testB` folder, and do the same for the `trainA` and `trainB` folders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lzSY8VuMamA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9baaa2-b42f-4306-fe16-9d2e575421af"
      },
      "source": [
        "!pip install gdown\n",
        "!gdown \"https://drive.google.com/uc?export=download&id=1FAOb7oYQo0XmyHmx2UznMxa-BW7yZCcJ\"\n",
        "\n",
        "# !gdown https://drive.google.com/uc?export=download&id=1FAOb7oYQo0XmyHmx2UznMxa-BW7yZCcJ"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2020.11.8)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1FAOb7oYQo0XmyHmx2UznMxa-BW7yZCcJ\n",
            "To: /content/pytorch-CycleGAN-and-pix2pix/sketch_impressionism.zip\n",
            "289MB [00:01, 197MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oR3AqrKudvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1516d87e-9f39-4af3-bba5-22d36afcbd78"
      },
      "source": [
        "!unzip 'sketch_impressionism.zip'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sketch_impressionism.zip\n",
            "   creating: sketch_impressionism/\n",
            "  inflating: __MACOSX/._sketch_impressionism  \n",
            "   creating: sketch_impressionism/trainB/\n",
            "  inflating: __MACOSX/sketch_impressionism/._trainB  \n",
            "   creating: sketch_impressionism/trainA/\n",
            "  inflating: __MACOSX/sketch_impressionism/._trainA  \n",
            "  inflating: sketch_impressionism/trainB/00080_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00028_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00025_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00046_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00179_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00110_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00056_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00165_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00035_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00038_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00090_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00100_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00153_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00130_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00154_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00195_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00005_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00066_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00006_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00211_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00185_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00120_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00188_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00143_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00201_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00018_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00198_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00076_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00123_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00207_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00140_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00186_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00075_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00016_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/.DS_Store  \n",
            "  inflating: __MACOSX/sketch_impressionism/trainB/._.DS_Store  \n",
            "  inflating: sketch_impressionism/trainB/00202_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00178_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00078_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00196_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00150_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00133_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00212_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00068_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00065_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00058_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00093_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00055_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00036_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00103_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00160_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00026_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00045_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00161_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00083_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00048_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00170_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00113_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00108_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00166_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00105_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00183_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00095_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00001_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00098_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00030_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00053_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00115_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00176_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00118_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00043_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00020_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00088_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00085_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00010_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00209_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00073_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00204_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00146_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00125_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00004_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00180_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00128_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00214_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00063_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00138_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00190_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00135_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00156_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00060_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00003_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00217_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00136_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00155_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00193_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00070_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00148_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00145_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00126_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00187_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00200_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00116_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00175_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00157_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00086_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00040_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00023_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00106_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00168_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00163_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00033_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00050_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00096_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00206_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00071_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00182_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00149_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00127_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00144_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00002_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00061_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00215_Impressionism.JPG  \n",
            "  inflating: sketch_impressionism/trainB/00216_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00137_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00159_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00192_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00107_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00009_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00164_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00173_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00051_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00032_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00097_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00117_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00210_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00087_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00022_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00015_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00041_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00177_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00114_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00119_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00021_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00089_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00042_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00084_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00109_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00104_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00167_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00011_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00094_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00052_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00099_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00031_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00008_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00172_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00062_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00139_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00191_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00134_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00072_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00208_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00205_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00124_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00147_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00181_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00129_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00014_Impressionism.jpg  \n",
            "  inflating: __MACOSX/sketch_impressionism/trainB/._00014_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00197_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00174_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00132_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00151_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00069_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00213_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00064_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00007_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00141_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00122_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00012_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00017_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00074_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00079_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00203_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00044_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00027_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00049_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00082_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00171_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00112_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00189_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00092_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00059_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00037_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00054_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00102_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00034_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00057_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00039_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00091_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00162_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00101_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00081_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00029_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00047_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00024_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00013_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00111_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00169_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00184_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00142_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00121_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00019_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00158_Impressionism.jpg  \n",
            "  inflating: sketch_impressionism/trainB/00077_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00199_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00131_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00152_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00194_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainB/00067_Impressionism.jpeg  \n",
            "  inflating: sketch_impressionism/trainA/00065_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00181_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00206_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00151_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00179_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00137_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00003_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00051_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00081_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00165_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00103_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00079_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00037_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00203_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00154_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00060_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00184_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00048_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00006_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00098_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00132_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00084_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00160_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00054_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00032_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00198_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00148_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00106_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00064_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00180_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00207_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00150_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00136_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00178_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/.DS_Store  \n",
            "  inflating: __MACOSX/sketch_impressionism/trainA/._.DS_Store  \n",
            "  inflating: sketch_impressionism/trainA/00002_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00050_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00080_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00164_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00102_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00036_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00078_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00202_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00155_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00061_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00185_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00007_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00049_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00099_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00133_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00085_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00161_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00055_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00033_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00199_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00107_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00149_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00183_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00029_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00067_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00153_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00204_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00135_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00001_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00053_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00129_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00167_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00083_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00101_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00035_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00118_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00156_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00201_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00186_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00062_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00004_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00130_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00162_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00086_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00018_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00056_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00030_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00104_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00182_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00066_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00028_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00152_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00205_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00134_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00052_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00166_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00128_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00082_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00100_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00034_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00157_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00119_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00200_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00187_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00063_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00005_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00131_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00163_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00087_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00057_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00019_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00031_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00105_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00042_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00092_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00138_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00176_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00209_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00110_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00024_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00038_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00076_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00192_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00215_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00142_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00124_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00010_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00097_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00173_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00009_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00047_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00021_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00115_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00210_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00109_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00147_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00073_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00197_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00015_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00121_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00043_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00093_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00177_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00139_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00208_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00111_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00025_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00077_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00039_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00193_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00214_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00143_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00125_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00011_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00096_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00172_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00046_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00008_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00020_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00114_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00211_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00146_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00108_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00072_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00196_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00014_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00120_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00040_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00174_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00090_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00112_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00068_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00026_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00190_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00074_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00140_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00217_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00168_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00126_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00012_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00171_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00095_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00045_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00189_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00023_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00159_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00117_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00145_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00212_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00195_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00071_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00059_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00017_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00123_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00089_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00041_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00175_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00091_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00113_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00027_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00069_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00191_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00075_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00141_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00216_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00127_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00169_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00013_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00170_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00094_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00044_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00188_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00022_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00116_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00158_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00144_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00213_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00194_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00070_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00016_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00058_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00122_Impressionism.png  \n",
            "  inflating: sketch_impressionism/trainA/00088_Impressionism.png  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFw1kDQBx3LN"
      },
      "source": [
        "# Training\n",
        "\n",
        "-   `python train.py --dataroot ./datasets/horse2zebra --name horse2zebra --model cycle_gan`\n",
        "\n",
        "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. I've found that a batch size of 16 fits onto 4 V100s and can finish training an epoch in ~90s.\n",
        "\n",
        "Once your model has trained, copy over the last checkpoint to a format that the testing model can automatically detect:\n",
        "\n",
        "Use `cp ./checkpoints/horse2zebra/latest_net_G_A.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class A to class B and `cp ./checkpoints/horse2zebra/latest_net_G_B.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class B to class A.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sp7TCT2x9dB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07d0aaca-6b99-40e1-ab99-c22fdad1e713"
      },
      "source": [
        "!python train.py --dataroot ./sketch_impressionism --name sketch_to_impressionism --model cycle_gan --checkpoints_dir /content/drive/MyDrive/0-Colab-Assets/train_cycleGAN --gpu_ids 0"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: /content/drive/MyDrive/0-Colab-Assets/train_cycleGAN\t[default: ./checkpoints]\n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./sketch_impressionism        \t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cycle_gan                     \n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: sketch_to_impressionism       \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "The number of training images = 217\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [CycleGANModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 11.378 M\n",
            "[Network G_B] Total number of parameters : 11.378 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "Setting up a new session...\n",
            "Exception in user code:\n",
            "------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 159, in _new_conn\n",
            "    (self._dns_host, self.port), self.timeout, **extra_kw)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\", line 80, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\", line 70, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
            "    chunked=chunked)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
            "    conn.request(method, url, **httplib_request_kw)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1042, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 980, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 181, in connect\n",
            "    conn = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 168, in _new_conn\n",
            "    self, \"Failed to establish a new connection: %s\" % e)\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9bb2c5ddd8>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/adapters.py\", line 449, in send\n",
            "    timeout=timeout\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
            "    _stacktrace=sys.exc_info()[2])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/retry.py\", line 399, in increment\n",
            "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9bb2c5ddd8>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/__init__.py\", line 711, in _send\n",
            "    data=json.dumps(msg),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/__init__.py\", line 677, in _handle_post\n",
            "    r = self.session.post(url, data=data)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 578, in post\n",
            "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 530, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 643, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/adapters.py\", line 516, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9bb2c5ddd8>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
            "[Errno 99] Cannot assign requested address\n",
            "[Errno 99] Cannot assign requested address\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
            "\n",
            "\n",
            "Could not connect to Visdom server. \n",
            " Trying to start a server....\n",
            "Command: /usr/bin/python3 -m visdom.server -p 8097 &>/dev/null &\n",
            "create web directory /content/drive/MyDrive/0-Colab-Assets/train_cycleGAN/sketch_to_impressionism/web...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "[Errno 99] Cannot assign requested address\n",
            "(epoch: 1, iters: 100, time: 0.331, data: 0.429) D_A: 0.358 G_A: 0.536 cycle_A: 0.631 idt_A: 1.774 D_B: 0.381 G_B: 0.518 cycle_B: 3.208 idt_B: 0.312 \n",
            "(epoch: 1, iters: 200, time: 0.332, data: 0.002) D_A: 0.214 G_A: 0.368 cycle_A: 1.717 idt_A: 0.968 D_B: 0.346 G_B: 0.437 cycle_B: 2.023 idt_B: 0.822 \n",
            "End of epoch 1 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 83, time: 0.332, data: 0.002) D_A: 0.285 G_A: 0.379 cycle_A: 0.879 idt_A: 1.875 D_B: 0.207 G_B: 0.411 cycle_B: 3.661 idt_B: 0.397 \n",
            "(epoch: 2, iters: 183, time: 0.733, data: 0.002) D_A: 0.287 G_A: 0.468 cycle_A: 0.884 idt_A: 1.115 D_B: 0.155 G_B: 0.297 cycle_B: 2.376 idt_B: 0.362 \n",
            "End of epoch 2 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 66, time: 0.329, data: 0.002) D_A: 0.125 G_A: 0.489 cycle_A: 1.046 idt_A: 1.392 D_B: 0.161 G_B: 0.265 cycle_B: 3.048 idt_B: 0.411 \n",
            "(epoch: 3, iters: 166, time: 0.331, data: 0.002) D_A: 0.242 G_A: 0.232 cycle_A: 1.363 idt_A: 0.735 D_B: 0.224 G_B: 0.487 cycle_B: 1.999 idt_B: 0.584 \n",
            "End of epoch 3 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 49, time: 0.332, data: 0.002) D_A: 0.327 G_A: 0.349 cycle_A: 0.772 idt_A: 0.973 D_B: 0.178 G_B: 0.826 cycle_B: 2.499 idt_B: 0.252 \n",
            "(epoch: 4, iters: 149, time: 0.706, data: 0.002) D_A: 0.228 G_A: 0.289 cycle_A: 1.392 idt_A: 1.313 D_B: 0.296 G_B: 0.379 cycle_B: 3.441 idt_B: 0.578 \n",
            "End of epoch 4 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 32, time: 0.331, data: 0.002) D_A: 0.170 G_A: 0.163 cycle_A: 0.345 idt_A: 2.729 D_B: 0.096 G_B: 0.271 cycle_B: 5.043 idt_B: 0.127 \n",
            "(epoch: 5, iters: 132, time: 0.331, data: 0.002) D_A: 0.189 G_A: 0.422 cycle_A: 0.937 idt_A: 0.793 D_B: 0.361 G_B: 0.238 cycle_B: 1.705 idt_B: 0.431 \n",
            "saving the model at the end of epoch 5, iters 1085\n",
            "End of epoch 5 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 15, time: 0.333, data: 0.002) D_A: 0.292 G_A: 0.268 cycle_A: 0.724 idt_A: 0.886 D_B: 0.088 G_B: 0.267 cycle_B: 2.166 idt_B: 0.334 \n",
            "(epoch: 6, iters: 115, time: 0.757, data: 0.002) D_A: 0.275 G_A: 0.376 cycle_A: 2.243 idt_A: 1.009 D_B: 0.268 G_B: 0.599 cycle_B: 2.672 idt_B: 1.047 \n",
            "(epoch: 6, iters: 215, time: 0.331, data: 0.002) D_A: 0.245 G_A: 0.644 cycle_A: 0.726 idt_A: 1.222 D_B: 0.205 G_B: 0.473 cycle_B: 2.522 idt_B: 0.305 \n",
            "End of epoch 6 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 98, time: 0.332, data: 0.002) D_A: 0.303 G_A: 0.711 cycle_A: 1.292 idt_A: 0.878 D_B: 0.279 G_B: 0.607 cycle_B: 2.112 idt_B: 0.548 \n",
            "(epoch: 7, iters: 198, time: 0.332, data: 0.002) D_A: 0.315 G_A: 0.354 cycle_A: 0.979 idt_A: 0.734 D_B: 0.063 G_B: 0.465 cycle_B: 1.816 idt_B: 0.437 \n",
            "End of epoch 7 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 81, time: 0.768, data: 0.002) D_A: 0.233 G_A: 0.207 cycle_A: 1.073 idt_A: 1.076 D_B: 0.305 G_B: 1.158 cycle_B: 2.400 idt_B: 0.483 \n",
            "(epoch: 8, iters: 181, time: 0.332, data: 0.002) D_A: 0.327 G_A: 0.348 cycle_A: 0.598 idt_A: 1.387 D_B: 0.088 G_B: 0.581 cycle_B: 2.940 idt_B: 0.283 \n",
            "End of epoch 8 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 64, time: 0.332, data: 0.002) D_A: 0.203 G_A: 0.322 cycle_A: 0.782 idt_A: 1.173 D_B: 0.236 G_B: 0.393 cycle_B: 2.482 idt_B: 0.309 \n",
            "(epoch: 9, iters: 164, time: 0.332, data: 0.002) D_A: 0.222 G_A: 0.483 cycle_A: 0.930 idt_A: 1.436 D_B: 0.308 G_B: 1.364 cycle_B: 2.724 idt_B: 0.382 \n",
            "End of epoch 9 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 47, time: 0.777, data: 0.002) D_A: 0.132 G_A: 0.560 cycle_A: 0.682 idt_A: 1.124 D_B: 0.030 G_B: 1.084 cycle_B: 2.365 idt_B: 0.284 \n",
            "(epoch: 10, iters: 147, time: 0.331, data: 0.002) D_A: 0.374 G_A: 0.137 cycle_A: 2.201 idt_A: 0.765 D_B: 0.416 G_B: 0.819 cycle_B: 1.971 idt_B: 1.066 \n",
            "saving the model at the end of epoch 10, iters 2170\n",
            "End of epoch 10 / 200 \t Time Taken: 72 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 30, time: 0.331, data: 0.002) D_A: 0.180 G_A: 0.547 cycle_A: 0.862 idt_A: 0.845 D_B: 0.052 G_B: 1.093 cycle_B: 1.877 idt_B: 0.326 \n",
            "(epoch: 11, iters: 130, time: 0.331, data: 0.001) D_A: 0.112 G_A: 0.436 cycle_A: 0.954 idt_A: 1.779 D_B: 0.022 G_B: 0.776 cycle_B: 4.556 idt_B: 0.387 \n",
            "End of epoch 11 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 13, time: 0.757, data: 0.002) D_A: 0.171 G_A: 0.217 cycle_A: 0.106 idt_A: 0.829 D_B: 0.161 G_B: 0.284 cycle_B: 1.682 idt_B: 0.040 \n",
            "(epoch: 12, iters: 113, time: 0.332, data: 0.002) D_A: 0.243 G_A: 0.407 cycle_A: 0.683 idt_A: 0.651 D_B: 0.096 G_B: 1.432 cycle_B: 1.565 idt_B: 0.319 \n",
            "(epoch: 12, iters: 213, time: 0.332, data: 0.002) D_A: 0.172 G_A: 0.571 cycle_A: 0.532 idt_A: 0.744 D_B: 0.103 G_B: 0.315 cycle_B: 1.691 idt_B: 0.263 \n",
            "End of epoch 12 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 96, time: 0.332, data: 0.002) D_A: 0.487 G_A: 0.353 cycle_A: 0.592 idt_A: 0.588 D_B: 0.340 G_B: 0.151 cycle_B: 1.651 idt_B: 0.206 \n",
            "(epoch: 13, iters: 196, time: 0.818, data: 0.002) D_A: 0.116 G_A: 0.534 cycle_A: 0.912 idt_A: 1.120 D_B: 0.063 G_B: 0.540 cycle_B: 2.631 idt_B: 0.438 \n",
            "End of epoch 13 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 79, time: 0.332, data: 0.002) D_A: 0.175 G_A: 0.297 cycle_A: 0.405 idt_A: 0.768 D_B: 0.109 G_B: 0.870 cycle_B: 1.799 idt_B: 0.173 \n",
            "(epoch: 14, iters: 179, time: 0.332, data: 0.002) D_A: 0.185 G_A: 0.206 cycle_A: 1.016 idt_A: 1.247 D_B: 0.055 G_B: 1.213 cycle_B: 2.203 idt_B: 0.386 \n",
            "End of epoch 14 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 62, time: 0.332, data: 0.002) D_A: 0.356 G_A: 0.284 cycle_A: 0.314 idt_A: 0.780 D_B: 0.061 G_B: 1.277 cycle_B: 2.067 idt_B: 0.117 \n",
            "(epoch: 15, iters: 162, time: 0.847, data: 0.002) D_A: 0.345 G_A: 0.238 cycle_A: 0.575 idt_A: 0.741 D_B: 0.381 G_B: 0.250 cycle_B: 1.946 idt_B: 0.159 \n",
            "saving the model at the end of epoch 15, iters 3255\n",
            "End of epoch 15 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 45, time: 0.332, data: 0.002) D_A: 0.240 G_A: 0.415 cycle_A: 0.376 idt_A: 1.099 D_B: 0.271 G_B: 0.137 cycle_B: 2.547 idt_B: 0.166 \n",
            "(epoch: 16, iters: 145, time: 0.331, data: 0.002) D_A: 0.146 G_A: 0.357 cycle_A: 1.354 idt_A: 0.736 D_B: 0.148 G_B: 0.491 cycle_B: 2.724 idt_B: 0.619 \n",
            "End of epoch 16 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 28, time: 0.331, data: 0.002) D_A: 0.348 G_A: 0.212 cycle_A: 1.114 idt_A: 1.125 D_B: 0.113 G_B: 1.273 cycle_B: 2.890 idt_B: 0.505 \n",
            "(epoch: 17, iters: 128, time: 0.871, data: 0.003) D_A: 0.180 G_A: 0.199 cycle_A: 0.731 idt_A: 0.814 D_B: 0.084 G_B: 0.388 cycle_B: 1.912 idt_B: 0.317 \n",
            "End of epoch 17 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 11, time: 0.331, data: 0.002) D_A: 0.178 G_A: 0.268 cycle_A: 0.180 idt_A: 0.979 D_B: 0.094 G_B: 0.386 cycle_B: 2.085 idt_B: 0.070 \n",
            "(epoch: 18, iters: 111, time: 0.330, data: 0.002) D_A: 0.123 G_A: 0.421 cycle_A: 1.286 idt_A: 1.009 D_B: 0.030 G_B: 0.523 cycle_B: 2.463 idt_B: 0.577 \n",
            "(epoch: 18, iters: 211, time: 0.331, data: 0.002) D_A: 0.366 G_A: 0.984 cycle_A: 1.106 idt_A: 0.770 D_B: 0.076 G_B: 0.391 cycle_B: 1.940 idt_B: 0.444 \n",
            "End of epoch 18 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 94, time: 0.847, data: 0.002) D_A: 0.179 G_A: 0.223 cycle_A: 0.582 idt_A: 0.627 D_B: 0.058 G_B: 0.782 cycle_B: 1.559 idt_B: 0.203 \n",
            "(epoch: 19, iters: 194, time: 0.331, data: 0.002) D_A: 0.178 G_A: 0.337 cycle_A: 0.614 idt_A: 0.870 D_B: 0.062 G_B: 0.879 cycle_B: 1.531 idt_B: 0.251 \n",
            "End of epoch 19 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 77, time: 0.331, data: 0.002) D_A: 0.216 G_A: 0.302 cycle_A: 1.399 idt_A: 0.655 D_B: 0.019 G_B: 0.635 cycle_B: 1.644 idt_B: 0.547 \n",
            "(epoch: 20, iters: 177, time: 0.332, data: 0.002) D_A: 0.286 G_A: 0.320 cycle_A: 0.759 idt_A: 0.980 D_B: 0.133 G_B: 0.462 cycle_B: 2.246 idt_B: 0.225 \n",
            "saving the model at the end of epoch 20, iters 4340\n",
            "End of epoch 20 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 60, time: 0.893, data: 0.002) D_A: 0.447 G_A: 0.059 cycle_A: 0.997 idt_A: 1.251 D_B: 0.590 G_B: 0.609 cycle_B: 2.540 idt_B: 0.315 \n",
            "(epoch: 21, iters: 160, time: 0.332, data: 0.002) D_A: 0.244 G_A: 0.257 cycle_A: 0.704 idt_A: 0.844 D_B: 0.034 G_B: 1.141 cycle_B: 2.082 idt_B: 0.272 \n",
            "End of epoch 21 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 43, time: 0.333, data: 0.002) D_A: 0.137 G_A: 0.490 cycle_A: 0.862 idt_A: 0.676 D_B: 0.067 G_B: 0.937 cycle_B: 1.744 idt_B: 0.301 \n",
            "(epoch: 22, iters: 143, time: 0.331, data: 0.002) D_A: 0.304 G_A: 0.551 cycle_A: 0.608 idt_A: 0.794 D_B: 0.135 G_B: 0.756 cycle_B: 2.177 idt_B: 0.235 \n",
            "End of epoch 22 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 26, time: 0.874, data: 0.002) D_A: 0.334 G_A: 0.208 cycle_A: 0.379 idt_A: 1.604 D_B: 0.107 G_B: 0.772 cycle_B: 2.828 idt_B: 0.145 \n",
            "(epoch: 23, iters: 126, time: 0.331, data: 0.001) D_A: 0.250 G_A: 0.150 cycle_A: 0.623 idt_A: 1.238 D_B: 0.228 G_B: 0.791 cycle_B: 2.746 idt_B: 0.209 \n",
            "End of epoch 23 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 9, time: 0.331, data: 0.002) D_A: 0.225 G_A: 0.170 cycle_A: 0.694 idt_A: 0.762 D_B: 0.174 G_B: 0.254 cycle_B: 1.829 idt_B: 0.259 \n",
            "saving the latest model (epoch 24, total_iters 5000)\n",
            "(epoch: 24, iters: 109, time: 0.332, data: 0.002) D_A: 0.426 G_A: 0.174 cycle_A: 0.700 idt_A: 0.606 D_B: 0.303 G_B: 0.622 cycle_B: 1.701 idt_B: 0.192 \n",
            "(epoch: 24, iters: 209, time: 0.929, data: 0.002) D_A: 0.182 G_A: 0.272 cycle_A: 0.575 idt_A: 0.719 D_B: 0.169 G_B: 0.593 cycle_B: 1.766 idt_B: 0.206 \n",
            "End of epoch 24 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 92, time: 0.332, data: 0.002) D_A: 0.134 G_A: 0.375 cycle_A: 0.538 idt_A: 0.732 D_B: 0.126 G_B: 0.279 cycle_B: 1.712 idt_B: 0.179 \n",
            "(epoch: 25, iters: 192, time: 0.332, data: 0.002) D_A: 0.421 G_A: 0.152 cycle_A: 0.676 idt_A: 0.662 D_B: 0.227 G_B: 0.165 cycle_B: 1.714 idt_B: 0.205 \n",
            "saving the model at the end of epoch 25, iters 5425\n",
            "End of epoch 25 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 75, time: 0.332, data: 0.002) D_A: 0.130 G_A: 1.012 cycle_A: 0.886 idt_A: 0.628 D_B: 0.094 G_B: 0.625 cycle_B: 1.720 idt_B: 0.316 \n",
            "(epoch: 26, iters: 175, time: 0.897, data: 0.001) D_A: 0.338 G_A: 0.076 cycle_A: 0.390 idt_A: 1.052 D_B: 0.034 G_B: 1.127 cycle_B: 1.845 idt_B: 0.135 \n",
            "End of epoch 26 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 58, time: 0.331, data: 0.002) D_A: 0.237 G_A: 0.227 cycle_A: 0.397 idt_A: 0.922 D_B: 0.220 G_B: 0.850 cycle_B: 2.246 idt_B: 0.149 \n",
            "(epoch: 27, iters: 158, time: 0.332, data: 0.002) D_A: 0.140 G_A: 0.262 cycle_A: 1.031 idt_A: 0.626 D_B: 0.133 G_B: 0.932 cycle_B: 1.907 idt_B: 0.376 \n",
            "End of epoch 27 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 41, time: 0.331, data: 0.002) D_A: 0.305 G_A: 0.095 cycle_A: 1.317 idt_A: 1.328 D_B: 0.094 G_B: 0.397 cycle_B: 2.735 idt_B: 0.556 \n",
            "(epoch: 28, iters: 141, time: 1.007, data: 0.002) D_A: 0.113 G_A: 0.450 cycle_A: 0.278 idt_A: 0.536 D_B: 0.271 G_B: 0.528 cycle_B: 1.257 idt_B: 0.103 \n",
            "End of epoch 28 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 24, time: 0.332, data: 0.002) D_A: 0.230 G_A: 0.024 cycle_A: 0.708 idt_A: 0.656 D_B: 0.218 G_B: 0.628 cycle_B: 1.684 idt_B: 0.279 \n",
            "(epoch: 29, iters: 124, time: 0.332, data: 0.002) D_A: 0.065 G_A: 0.156 cycle_A: 0.792 idt_A: 0.714 D_B: 0.088 G_B: 0.811 cycle_B: 1.728 idt_B: 0.293 \n",
            "End of epoch 29 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 7, time: 0.331, data: 0.002) D_A: 0.383 G_A: 0.051 cycle_A: 0.509 idt_A: 0.702 D_B: 0.156 G_B: 0.952 cycle_B: 1.493 idt_B: 0.184 \n",
            "(epoch: 30, iters: 107, time: 0.968, data: 0.002) D_A: 0.578 G_A: 0.047 cycle_A: 0.498 idt_A: 0.687 D_B: 0.062 G_B: 1.063 cycle_B: 1.556 idt_B: 0.163 \n",
            "(epoch: 30, iters: 207, time: 0.332, data: 0.002) D_A: 0.163 G_A: 0.300 cycle_A: 0.774 idt_A: 0.748 D_B: 0.032 G_B: 0.076 cycle_B: 2.175 idt_B: 0.279 \n",
            "saving the model at the end of epoch 30, iters 6510\n",
            "End of epoch 30 / 200 \t Time Taken: 71 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 90, time: 0.331, data: 0.002) D_A: 0.176 G_A: 0.205 cycle_A: 0.929 idt_A: 0.510 D_B: 0.431 G_B: 1.413 cycle_B: 1.312 idt_B: 0.319 \n",
            "(epoch: 31, iters: 190, time: 0.331, data: 0.002) D_A: 0.225 G_A: 0.693 cycle_A: 0.764 idt_A: 0.874 D_B: 0.084 G_B: 0.479 cycle_B: 2.157 idt_B: 0.328 \n",
            "End of epoch 31 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 73, time: 0.983, data: 0.002) D_A: 0.219 G_A: 0.463 cycle_A: 0.647 idt_A: 0.707 D_B: 0.019 G_B: 1.082 cycle_B: 1.923 idt_B: 0.234 \n",
            "(epoch: 32, iters: 173, time: 0.331, data: 0.002) D_A: 0.177 G_A: 0.251 cycle_A: 0.491 idt_A: 0.968 D_B: 0.067 G_B: 0.531 cycle_B: 2.292 idt_B: 0.155 \n",
            "End of epoch 32 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 56, time: 0.331, data: 0.002) D_A: 0.318 G_A: 0.294 cycle_A: 0.907 idt_A: 0.555 D_B: 0.177 G_B: 0.222 cycle_B: 1.413 idt_B: 0.321 \n",
            "(epoch: 33, iters: 156, time: 0.330, data: 0.002) D_A: 0.084 G_A: 0.195 cycle_A: 0.429 idt_A: 0.554 D_B: 0.223 G_B: 0.531 cycle_B: 1.557 idt_B: 0.144 \n",
            "End of epoch 33 / 200 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 39, time: 0.952, data: 0.001) D_A: 0.130 G_A: 0.268 cycle_A: 0.420 idt_A: 0.617 D_B: 0.118 G_B: 1.563 cycle_B: 1.557 idt_B: 0.145 \n",
            "(epoch: 34, iters: 139, time: 0.330, data: 0.002) D_A: 0.380 G_A: 0.051 cycle_A: 0.952 idt_A: 0.446 D_B: 0.292 G_B: 0.328 cycle_B: 1.375 idt_B: 0.338 \n",
            "End of epoch 34 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 22, time: 0.331, data: 0.002) D_A: 0.220 G_A: 0.074 cycle_A: 1.248 idt_A: 0.851 D_B: 0.126 G_B: 0.401 cycle_B: 2.278 idt_B: 0.484 \n",
            "(epoch: 35, iters: 122, time: 0.331, data: 0.002) D_A: 0.229 G_A: 0.575 cycle_A: 0.587 idt_A: 0.562 D_B: 0.173 G_B: 0.313 cycle_B: 1.453 idt_B: 0.250 \n",
            "saving the model at the end of epoch 35, iters 7595\n",
            "End of epoch 35 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 5, time: 0.998, data: 0.002) D_A: 0.205 G_A: 0.120 cycle_A: 0.616 idt_A: 0.768 D_B: 0.080 G_B: 0.442 cycle_B: 2.002 idt_B: 0.141 \n",
            "(epoch: 36, iters: 105, time: 0.332, data: 0.002) D_A: 0.243 G_A: 0.216 cycle_A: 0.602 idt_A: 0.785 D_B: 0.053 G_B: 0.285 cycle_B: 1.905 idt_B: 0.225 \n",
            "(epoch: 36, iters: 205, time: 0.331, data: 0.002) D_A: 0.239 G_A: 0.048 cycle_A: 0.694 idt_A: 0.462 D_B: 0.084 G_B: 0.435 cycle_B: 1.387 idt_B: 0.263 \n",
            "End of epoch 36 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 88, time: 0.332, data: 0.002) D_A: 0.149 G_A: 0.466 cycle_A: 0.819 idt_A: 0.482 D_B: 0.049 G_B: 0.089 cycle_B: 1.384 idt_B: 0.296 \n",
            "(epoch: 37, iters: 188, time: 1.025, data: 0.002) D_A: 0.304 G_A: 0.099 cycle_A: 0.338 idt_A: 0.577 D_B: 0.064 G_B: 0.057 cycle_B: 1.579 idt_B: 0.120 \n",
            "End of epoch 37 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 71, time: 0.331, data: 0.002) D_A: 0.283 G_A: 0.528 cycle_A: 1.203 idt_A: 1.024 D_B: 0.029 G_B: 0.365 cycle_B: 2.406 idt_B: 0.423 \n",
            "(epoch: 38, iters: 171, time: 0.330, data: 0.002) D_A: 0.101 G_A: 0.651 cycle_A: 0.408 idt_A: 0.854 D_B: 0.070 G_B: 0.646 cycle_B: 1.999 idt_B: 0.115 \n",
            "End of epoch 38 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 54, time: 0.330, data: 0.002) D_A: 0.151 G_A: 0.355 cycle_A: 0.578 idt_A: 0.883 D_B: 0.016 G_B: 0.937 cycle_B: 2.378 idt_B: 0.210 \n",
            "(epoch: 39, iters: 154, time: 1.086, data: 0.002) D_A: 0.212 G_A: 0.260 cycle_A: 0.837 idt_A: 0.473 D_B: 0.168 G_B: 0.243 cycle_B: 1.326 idt_B: 0.246 \n",
            "End of epoch 39 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 37, time: 0.331, data: 0.002) D_A: 0.069 G_A: 0.178 cycle_A: 0.756 idt_A: 0.412 D_B: 0.009 G_B: 0.947 cycle_B: 1.347 idt_B: 0.269 \n",
            "(epoch: 40, iters: 137, time: 0.329, data: 0.002) D_A: 0.184 G_A: 0.159 cycle_A: 0.282 idt_A: 0.554 D_B: 0.041 G_B: 0.538 cycle_B: 1.777 idt_B: 0.098 \n",
            "saving the model at the end of epoch 40, iters 8680\n",
            "End of epoch 40 / 200 \t Time Taken: 71 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 20, time: 0.337, data: 0.002) D_A: 0.269 G_A: 0.331 cycle_A: 0.529 idt_A: 0.527 D_B: 0.248 G_B: 0.148 cycle_B: 1.556 idt_B: 0.183 \n",
            "(epoch: 41, iters: 120, time: 1.060, data: 0.003) D_A: 0.219 G_A: 0.164 cycle_A: 0.826 idt_A: 0.534 D_B: 0.226 G_B: 0.279 cycle_B: 1.633 idt_B: 0.270 \n",
            "End of epoch 41 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 3, time: 0.331, data: 0.002) D_A: 0.123 G_A: 0.175 cycle_A: 1.183 idt_A: 0.421 D_B: 0.271 G_B: 0.582 cycle_B: 1.218 idt_B: 0.446 \n",
            "(epoch: 42, iters: 103, time: 0.330, data: 0.000) D_A: 0.306 G_A: 0.205 cycle_A: 0.417 idt_A: 0.708 D_B: 0.017 G_B: 0.621 cycle_B: 1.974 idt_B: 0.132 \n",
            "(epoch: 42, iters: 203, time: 0.331, data: 0.002) D_A: 0.169 G_A: 0.394 cycle_A: 0.681 idt_A: 0.533 D_B: 0.022 G_B: 0.843 cycle_B: 1.280 idt_B: 0.263 \n",
            "End of epoch 42 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 86, time: 1.150, data: 0.002) D_A: 0.226 G_A: 0.186 cycle_A: 0.344 idt_A: 0.402 D_B: 0.009 G_B: 0.966 cycle_B: 0.957 idt_B: 0.104 \n",
            "(epoch: 43, iters: 186, time: 0.330, data: 0.002) D_A: 0.274 G_A: 0.117 cycle_A: 0.466 idt_A: 0.502 D_B: 0.228 G_B: 0.579 cycle_B: 1.216 idt_B: 0.150 \n",
            "End of epoch 43 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 69, time: 0.329, data: 0.003) D_A: 0.270 G_A: 0.288 cycle_A: 0.374 idt_A: 0.663 D_B: 0.061 G_B: 0.673 cycle_B: 1.783 idt_B: 0.124 \n",
            "(epoch: 44, iters: 169, time: 0.330, data: 0.002) D_A: 0.120 G_A: 0.113 cycle_A: 0.654 idt_A: 0.656 D_B: 0.055 G_B: 0.541 cycle_B: 1.594 idt_B: 0.241 \n",
            "End of epoch 44 / 200 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 52, time: 1.084, data: 0.002) D_A: 0.364 G_A: 0.127 cycle_A: 0.226 idt_A: 0.679 D_B: 0.119 G_B: 0.573 cycle_B: 1.458 idt_B: 0.085 \n",
            "(epoch: 45, iters: 152, time: 0.330, data: 0.002) D_A: 0.370 G_A: 0.097 cycle_A: 1.083 idt_A: 0.757 D_B: 0.094 G_B: 0.383 cycle_B: 1.765 idt_B: 0.400 \n",
            "saving the model at the end of epoch 45, iters 9765\n",
            "End of epoch 45 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 35, time: 0.328, data: 0.002) D_A: 0.205 G_A: 0.279 cycle_A: 0.768 idt_A: 0.508 D_B: 0.022 G_B: 0.637 cycle_B: 1.639 idt_B: 0.226 \n",
            "(epoch: 46, iters: 135, time: 0.331, data: 0.002) D_A: 0.130 G_A: 0.113 cycle_A: 0.588 idt_A: 0.582 D_B: 0.024 G_B: 0.729 cycle_B: 1.616 idt_B: 0.197 \n",
            "End of epoch 46 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 18, time: 1.175, data: 0.002) D_A: 0.102 G_A: 0.296 cycle_A: 0.865 idt_A: 0.953 D_B: 0.126 G_B: 0.299 cycle_B: 2.354 idt_B: 0.355 \n",
            "saving the latest model (epoch 47, total_iters 10000)\n",
            "(epoch: 47, iters: 118, time: 0.328, data: 0.002) D_A: 0.226 G_A: 0.206 cycle_A: 0.781 idt_A: 0.420 D_B: 0.355 G_B: 0.066 cycle_B: 1.321 idt_B: 0.268 \n",
            "End of epoch 47 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 1, time: 0.329, data: 0.002) D_A: 0.250 G_A: 0.432 cycle_A: 0.604 idt_A: 0.434 D_B: 0.032 G_B: 0.207 cycle_B: 1.108 idt_B: 0.196 \n",
            "(epoch: 48, iters: 101, time: 0.330, data: 0.002) D_A: 0.259 G_A: 0.360 cycle_A: 0.725 idt_A: 0.731 D_B: 0.383 G_B: 0.085 cycle_B: 1.739 idt_B: 0.214 \n",
            "(epoch: 48, iters: 201, time: 1.157, data: 0.002) D_A: 0.196 G_A: 0.098 cycle_A: 0.747 idt_A: 0.551 D_B: 0.383 G_B: 0.966 cycle_B: 1.611 idt_B: 0.200 \n",
            "End of epoch 48 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 84, time: 0.330, data: 0.002) D_A: 0.209 G_A: 0.512 cycle_A: 0.461 idt_A: 0.565 D_B: 0.010 G_B: 0.957 cycle_B: 1.859 idt_B: 0.130 \n",
            "(epoch: 49, iters: 184, time: 0.330, data: 0.002) D_A: 0.359 G_A: 0.375 cycle_A: 0.459 idt_A: 0.537 D_B: 0.411 G_B: 0.036 cycle_B: 1.434 idt_B: 0.151 \n",
            "End of epoch 49 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 67, time: 0.331, data: 0.002) D_A: 0.393 G_A: 0.112 cycle_A: 0.560 idt_A: 0.434 D_B: 0.260 G_B: 0.310 cycle_B: 1.262 idt_B: 0.197 \n",
            "(epoch: 50, iters: 167, time: 1.199, data: 0.002) D_A: 0.216 G_A: 0.138 cycle_A: 0.812 idt_A: 0.257 D_B: 0.073 G_B: 0.872 cycle_B: 0.947 idt_B: 0.187 \n",
            "saving the model at the end of epoch 50, iters 10850\n",
            "End of epoch 50 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 51, iters: 50, time: 0.330, data: 0.002) D_A: 0.208 G_A: 0.281 cycle_A: 0.827 idt_A: 0.426 D_B: 0.162 G_B: 0.232 cycle_B: 1.429 idt_B: 0.328 \n",
            "(epoch: 51, iters: 150, time: 0.330, data: 0.002) D_A: 0.149 G_A: 0.434 cycle_A: 0.806 idt_A: 0.546 D_B: 0.055 G_B: 1.517 cycle_B: 1.394 idt_B: 0.312 \n",
            "End of epoch 51 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 33, time: 0.331, data: 0.002) D_A: 0.306 G_A: 0.109 cycle_A: 0.782 idt_A: 0.366 D_B: 0.027 G_B: 0.679 cycle_B: 1.091 idt_B: 0.288 \n",
            "(epoch: 52, iters: 133, time: 1.157, data: 0.002) D_A: 0.230 G_A: 0.655 cycle_A: 0.429 idt_A: 0.513 D_B: 0.010 G_B: 0.831 cycle_B: 1.381 idt_B: 0.127 \n",
            "End of epoch 52 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 16, time: 0.330, data: 0.002) D_A: 0.304 G_A: 0.236 cycle_A: 0.681 idt_A: 0.456 D_B: 0.049 G_B: 0.587 cycle_B: 1.509 idt_B: 0.209 \n",
            "(epoch: 53, iters: 116, time: 0.330, data: 0.002) D_A: 0.246 G_A: 0.042 cycle_A: 0.526 idt_A: 0.590 D_B: 0.019 G_B: 0.761 cycle_B: 1.641 idt_B: 0.176 \n",
            "(epoch: 53, iters: 216, time: 0.330, data: 0.002) D_A: 0.406 G_A: 0.225 cycle_A: 0.415 idt_A: 0.430 D_B: 0.302 G_B: 0.300 cycle_B: 1.449 idt_B: 0.122 \n",
            "End of epoch 53 / 200 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 99, time: 1.177, data: 0.002) D_A: 0.224 G_A: 0.261 cycle_A: 0.543 idt_A: 0.694 D_B: 0.068 G_B: 0.449 cycle_B: 1.927 idt_B: 0.183 \n",
            "(epoch: 54, iters: 199, time: 0.328, data: 0.002) D_A: 0.265 G_A: 0.391 cycle_A: 0.496 idt_A: 0.496 D_B: 0.184 G_B: 0.202 cycle_B: 1.523 idt_B: 0.179 \n",
            "End of epoch 54 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 82, time: 0.330, data: 0.002) D_A: 0.348 G_A: 0.734 cycle_A: 0.948 idt_A: 0.451 D_B: 0.104 G_B: 0.414 cycle_B: 1.462 idt_B: 0.338 \n",
            "(epoch: 55, iters: 182, time: 0.329, data: 0.002) D_A: 0.274 G_A: 0.171 cycle_A: 0.246 idt_A: 0.455 D_B: 0.019 G_B: 0.781 cycle_B: 1.224 idt_B: 0.078 \n",
            "saving the model at the end of epoch 55, iters 11935\n",
            "End of epoch 55 / 200 \t Time Taken: 71 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 65, time: 1.232, data: 0.002) D_A: 0.160 G_A: 0.170 cycle_A: 1.044 idt_A: 1.302 D_B: 0.079 G_B: 1.492 cycle_B: 2.602 idt_B: 0.211 \n",
            "(epoch: 56, iters: 165, time: 0.329, data: 0.003) D_A: 0.127 G_A: 0.121 cycle_A: 0.423 idt_A: 0.657 D_B: 0.075 G_B: 1.248 cycle_B: 1.583 idt_B: 0.118 \n",
            "End of epoch 56 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 48, time: 0.330, data: 0.002) D_A: 0.118 G_A: 0.259 cycle_A: 0.339 idt_A: 0.516 D_B: 0.294 G_B: 0.071 cycle_B: 1.194 idt_B: 0.093 \n",
            "(epoch: 57, iters: 148, time: 0.330, data: 0.002) D_A: 0.117 G_A: 0.203 cycle_A: 0.270 idt_A: 0.487 D_B: 0.101 G_B: 1.052 cycle_B: 1.554 idt_B: 0.087 \n",
            "End of epoch 57 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 31, time: 1.242, data: 0.002) D_A: 0.345 G_A: 0.202 cycle_A: 0.729 idt_A: 0.819 D_B: 0.204 G_B: 0.403 cycle_B: 1.956 idt_B: 0.253 \n",
            "(epoch: 58, iters: 131, time: 0.330, data: 0.002) D_A: 0.130 G_A: 0.437 cycle_A: 0.618 idt_A: 0.438 D_B: 0.271 G_B: 0.347 cycle_B: 1.560 idt_B: 0.205 \n",
            "End of epoch 58 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 59, iters: 14, time: 0.330, data: 0.002) D_A: 0.136 G_A: 0.082 cycle_A: 0.363 idt_A: 0.515 D_B: 0.163 G_B: 0.323 cycle_B: 1.232 idt_B: 0.126 \n",
            "(epoch: 59, iters: 114, time: 0.330, data: 0.002) D_A: 0.184 G_A: 0.071 cycle_A: 0.183 idt_A: 0.537 D_B: 0.390 G_B: 0.355 cycle_B: 1.467 idt_B: 0.068 \n",
            "(epoch: 59, iters: 214, time: 1.236, data: 0.002) D_A: 0.247 G_A: 0.607 cycle_A: 0.772 idt_A: 0.534 D_B: 0.113 G_B: 0.436 cycle_B: 1.611 idt_B: 0.257 \n",
            "End of epoch 59 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 97, time: 0.330, data: 0.002) D_A: 0.189 G_A: 0.383 cycle_A: 0.974 idt_A: 0.513 D_B: 0.143 G_B: 0.873 cycle_B: 1.529 idt_B: 0.357 \n",
            "(epoch: 60, iters: 197, time: 0.329, data: 0.002) D_A: 0.283 G_A: 0.574 cycle_A: 1.097 idt_A: 0.531 D_B: 0.241 G_B: 0.140 cycle_B: 1.674 idt_B: 0.311 \n",
            "saving the model at the end of epoch 60, iters 13020\n",
            "End of epoch 60 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 80, time: 0.330, data: 0.002) D_A: 0.273 G_A: 0.142 cycle_A: 1.095 idt_A: 0.719 D_B: 0.111 G_B: 1.142 cycle_B: 1.504 idt_B: 0.419 \n",
            "(epoch: 61, iters: 180, time: 1.222, data: 0.002) D_A: 0.191 G_A: 0.340 cycle_A: 0.446 idt_A: 0.458 D_B: 0.093 G_B: 0.738 cycle_B: 1.169 idt_B: 0.102 \n",
            "End of epoch 61 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 63, time: 0.331, data: 0.002) D_A: 0.114 G_A: 0.198 cycle_A: 0.207 idt_A: 0.616 D_B: 0.170 G_B: 0.561 cycle_B: 1.084 idt_B: 0.060 \n",
            "(epoch: 62, iters: 163, time: 0.331, data: 0.002) D_A: 0.228 G_A: 0.335 cycle_A: 0.508 idt_A: 0.674 D_B: 0.140 G_B: 0.280 cycle_B: 1.771 idt_B: 0.164 \n",
            "End of epoch 62 / 200 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 46, time: 0.331, data: 0.002) D_A: 0.158 G_A: 0.287 cycle_A: 0.341 idt_A: 0.598 D_B: 0.113 G_B: 1.007 cycle_B: 1.811 idt_B: 0.102 \n",
            "(epoch: 63, iters: 146, time: 1.275, data: 0.002) D_A: 0.275 G_A: 0.252 cycle_A: 1.015 idt_A: 0.826 D_B: 0.022 G_B: 0.899 cycle_B: 2.405 idt_B: 0.399 \n",
            "End of epoch 63 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 29, time: 0.329, data: 0.002) D_A: 0.158 G_A: 0.194 cycle_A: 0.532 idt_A: 0.521 D_B: 0.130 G_B: 0.320 cycle_B: 1.929 idt_B: 0.166 \n",
            "(epoch: 64, iters: 129, time: 0.330, data: 0.002) D_A: 0.194 G_A: 0.330 cycle_A: 0.896 idt_A: 0.523 D_B: 0.090 G_B: 0.488 cycle_B: 0.940 idt_B: 0.382 \n",
            "End of epoch 64 / 200 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 12, time: 0.330, data: 0.002) D_A: 0.162 G_A: 0.420 cycle_A: 0.929 idt_A: 0.621 D_B: 0.028 G_B: 0.745 cycle_B: 1.372 idt_B: 0.343 \n",
            "(epoch: 65, iters: 112, time: 1.365, data: 0.002) D_A: 0.166 G_A: 0.305 cycle_A: 0.733 idt_A: 0.625 D_B: 0.024 G_B: 0.262 cycle_B: 1.614 idt_B: 0.266 \n",
            "(epoch: 65, iters: 212, time: 0.330, data: 0.002) D_A: 0.292 G_A: 0.347 cycle_A: 0.698 idt_A: 0.545 D_B: 0.183 G_B: 1.221 cycle_B: 1.322 idt_B: 0.209 \n",
            "saving the model at the end of epoch 65, iters 14105\n",
            "End of epoch 65 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 95, time: 0.330, data: 0.002) D_A: 0.221 G_A: 0.177 cycle_A: 0.838 idt_A: 0.467 D_B: 0.032 G_B: 0.570 cycle_B: 1.322 idt_B: 0.347 \n",
            "(epoch: 66, iters: 195, time: 0.330, data: 0.002) D_A: 0.321 G_A: 0.120 cycle_A: 0.413 idt_A: 0.510 D_B: 0.122 G_B: 0.298 cycle_B: 1.430 idt_B: 0.128 \n",
            "End of epoch 66 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 67, iters: 78, time: 1.322, data: 0.002) D_A: 0.183 G_A: 0.427 cycle_A: 0.434 idt_A: 0.490 D_B: 0.064 G_B: 1.114 cycle_B: 1.061 idt_B: 0.149 \n",
            "(epoch: 67, iters: 178, time: 0.330, data: 0.002) D_A: 0.286 G_A: 0.247 cycle_A: 0.498 idt_A: 0.489 D_B: 0.034 G_B: 0.986 cycle_B: 1.377 idt_B: 0.143 \n",
            "End of epoch 67 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 61, time: 0.330, data: 0.002) D_A: 0.421 G_A: 0.668 cycle_A: 0.827 idt_A: 0.902 D_B: 0.057 G_B: 0.906 cycle_B: 1.966 idt_B: 0.268 \n",
            "(epoch: 68, iters: 161, time: 0.330, data: 0.002) D_A: 0.182 G_A: 0.261 cycle_A: 1.322 idt_A: 0.455 D_B: 0.137 G_B: 0.297 cycle_B: 1.579 idt_B: 0.447 \n",
            "End of epoch 68 / 200 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 44, time: 1.304, data: 0.002) D_A: 0.273 G_A: 0.411 cycle_A: 0.708 idt_A: 0.472 D_B: 0.206 G_B: 0.403 cycle_B: 1.148 idt_B: 0.250 \n",
            "(epoch: 69, iters: 144, time: 0.331, data: 0.002) D_A: 0.181 G_A: 0.157 cycle_A: 0.728 idt_A: 0.488 D_B: 0.093 G_B: 0.259 cycle_B: 1.519 idt_B: 0.196 \n",
            "End of epoch 69 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 27, time: 0.330, data: 0.002) D_A: 0.374 G_A: 0.071 cycle_A: 0.774 idt_A: 0.404 D_B: 0.010 G_B: 0.673 cycle_B: 1.510 idt_B: 0.274 \n",
            "saving the latest model (epoch 70, total_iters 15000)\n",
            "(epoch: 70, iters: 127, time: 0.330, data: 0.002) D_A: 0.231 G_A: 0.560 cycle_A: 0.368 idt_A: 0.615 D_B: 0.183 G_B: 0.358 cycle_B: 1.565 idt_B: 0.113 \n",
            "saving the model at the end of epoch 70, iters 15190\n",
            "End of epoch 70 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 10, time: 1.436, data: 0.002) D_A: 0.173 G_A: 0.633 cycle_A: 0.454 idt_A: 0.452 D_B: 0.193 G_B: 0.307 cycle_B: 1.619 idt_B: 0.137 \n",
            "(epoch: 71, iters: 110, time: 0.328, data: 0.002) D_A: 0.122 G_A: 0.449 cycle_A: 0.661 idt_A: 0.597 D_B: 0.175 G_B: 0.086 cycle_B: 1.194 idt_B: 0.241 \n",
            "(epoch: 71, iters: 210, time: 0.330, data: 0.002) D_A: 0.214 G_A: 0.338 cycle_A: 0.585 idt_A: 0.453 D_B: 0.107 G_B: 0.386 cycle_B: 1.275 idt_B: 0.233 \n",
            "End of epoch 71 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 93, time: 0.331, data: 0.002) D_A: 0.137 G_A: 0.549 cycle_A: 0.576 idt_A: 0.462 D_B: 0.198 G_B: 0.280 cycle_B: 1.446 idt_B: 0.202 \n",
            "(epoch: 72, iters: 193, time: 1.379, data: 0.002) D_A: 0.185 G_A: 0.195 cycle_A: 0.248 idt_A: 0.418 D_B: 0.154 G_B: 0.361 cycle_B: 1.058 idt_B: 0.063 \n",
            "End of epoch 72 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 76, time: 0.330, data: 0.002) D_A: 0.252 G_A: 0.249 cycle_A: 0.344 idt_A: 0.715 D_B: 0.227 G_B: 0.893 cycle_B: 2.320 idt_B: 0.090 \n",
            "(epoch: 73, iters: 176, time: 0.329, data: 0.002) D_A: 0.143 G_A: 0.291 cycle_A: 0.724 idt_A: 0.432 D_B: 0.023 G_B: 0.959 cycle_B: 0.984 idt_B: 0.240 \n",
            "End of epoch 73 / 200 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 59, time: 0.330, data: 0.002) D_A: 0.314 G_A: 0.193 cycle_A: 0.941 idt_A: 0.420 D_B: 0.155 G_B: 0.214 cycle_B: 1.145 idt_B: 0.337 \n",
            "(epoch: 74, iters: 159, time: 1.308, data: 0.002) D_A: 0.215 G_A: 0.221 cycle_A: 0.604 idt_A: 0.591 D_B: 0.066 G_B: 0.586 cycle_B: 1.638 idt_B: 0.208 \n",
            "End of epoch 74 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 42, time: 0.331, data: 0.002) D_A: 0.136 G_A: 0.348 cycle_A: 0.433 idt_A: 0.461 D_B: 0.035 G_B: 0.651 cycle_B: 1.557 idt_B: 0.119 \n",
            "(epoch: 75, iters: 142, time: 0.330, data: 0.002) D_A: 0.190 G_A: 0.357 cycle_A: 0.338 idt_A: 0.339 D_B: 0.110 G_B: 0.227 cycle_B: 1.017 idt_B: 0.094 \n",
            "saving the model at the end of epoch 75, iters 16275\n",
            "End of epoch 75 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 76, iters: 25, time: 0.331, data: 0.002) D_A: 0.135 G_A: 0.135 cycle_A: 0.681 idt_A: 0.461 D_B: 0.049 G_B: 0.558 cycle_B: 1.331 idt_B: 0.217 \n",
            "(epoch: 76, iters: 125, time: 1.398, data: 0.002) D_A: 0.229 G_A: 0.233 cycle_A: 0.598 idt_A: 0.575 D_B: 0.062 G_B: 0.989 cycle_B: 1.516 idt_B: 0.192 \n",
            "End of epoch 76 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 8, time: 0.332, data: 0.002) D_A: 0.136 G_A: 0.370 cycle_A: 0.391 idt_A: 0.400 D_B: 0.085 G_B: 0.737 cycle_B: 1.059 idt_B: 0.121 \n",
            "(epoch: 77, iters: 108, time: 0.330, data: 0.002) D_A: 0.197 G_A: 0.257 cycle_A: 1.208 idt_A: 0.377 D_B: 0.174 G_B: 1.091 cycle_B: 1.287 idt_B: 0.410 \n",
            "(epoch: 77, iters: 208, time: 0.329, data: 0.002) D_A: 0.275 G_A: 0.095 cycle_A: 0.363 idt_A: 0.541 D_B: 0.194 G_B: 0.181 cycle_B: 1.675 idt_B: 0.116 \n",
            "End of epoch 77 / 200 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 91, time: 1.396, data: 0.002) D_A: 0.111 G_A: 0.382 cycle_A: 0.440 idt_A: 0.376 D_B: 0.339 G_B: 0.258 cycle_B: 1.356 idt_B: 0.140 \n",
            "(epoch: 78, iters: 191, time: 0.330, data: 0.002) D_A: 0.130 G_A: 0.174 cycle_A: 0.613 idt_A: 0.480 D_B: 0.112 G_B: 1.723 cycle_B: 1.519 idt_B: 0.174 \n",
            "End of epoch 78 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 74, time: 0.331, data: 0.002) D_A: 0.199 G_A: 0.369 cycle_A: 0.591 idt_A: 0.325 D_B: 0.013 G_B: 1.036 cycle_B: 1.150 idt_B: 0.165 \n",
            "(epoch: 79, iters: 174, time: 0.329, data: 0.002) D_A: 0.297 G_A: 0.511 cycle_A: 0.359 idt_A: 0.382 D_B: 0.388 G_B: 0.703 cycle_B: 1.144 idt_B: 0.104 \n",
            "End of epoch 79 / 200 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 57, time: 1.488, data: 0.002) D_A: 0.082 G_A: 0.349 cycle_A: 0.871 idt_A: 0.474 D_B: 0.043 G_B: 1.523 cycle_B: 1.583 idt_B: 0.334 \n",
            "(epoch: 80, iters: 157, time: 0.331, data: 0.002) D_A: 0.173 G_A: 0.635 cycle_A: 1.262 idt_A: 0.531 D_B: 0.167 G_B: 0.356 cycle_B: 1.461 idt_B: 0.544 \n",
            "saving the model at the end of epoch 80, iters 17360\n",
            "End of epoch 80 / 200 \t Time Taken: 73 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 40, time: 0.326, data: 0.002) D_A: 0.289 G_A: 0.266 cycle_A: 0.416 idt_A: 0.725 D_B: 0.016 G_B: 1.211 cycle_B: 1.797 idt_B: 0.109 \n",
            "(epoch: 81, iters: 140, time: 0.329, data: 0.002) D_A: 0.243 G_A: 0.258 cycle_A: 0.577 idt_A: 0.496 D_B: 0.040 G_B: 0.280 cycle_B: 1.521 idt_B: 0.202 \n",
            "End of epoch 81 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 23, time: 1.418, data: 0.002) D_A: 0.153 G_A: 0.225 cycle_A: 0.279 idt_A: 0.383 D_B: 0.021 G_B: 0.639 cycle_B: 1.122 idt_B: 0.080 \n",
            "(epoch: 82, iters: 123, time: 0.330, data: 0.002) D_A: 0.300 G_A: 0.251 cycle_A: 0.670 idt_A: 0.577 D_B: 0.071 G_B: 0.419 cycle_B: 1.233 idt_B: 0.204 \n",
            "End of epoch 82 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 6, time: 0.332, data: 0.002) D_A: 0.216 G_A: 0.379 cycle_A: 0.528 idt_A: 0.496 D_B: 0.456 G_B: 0.179 cycle_B: 1.360 idt_B: 0.157 \n",
            "(epoch: 83, iters: 106, time: 0.329, data: 0.000) D_A: 0.181 G_A: 0.291 cycle_A: 0.581 idt_A: 0.414 D_B: 0.187 G_B: 0.123 cycle_B: 1.311 idt_B: 0.177 \n",
            "(epoch: 83, iters: 206, time: 1.341, data: 0.002) D_A: 0.295 G_A: 0.309 cycle_A: 0.224 idt_A: 0.611 D_B: 0.198 G_B: 0.289 cycle_B: 1.391 idt_B: 0.063 \n",
            "End of epoch 83 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 84, iters: 89, time: 0.330, data: 0.002) D_A: 0.290 G_A: 0.204 cycle_A: 0.967 idt_A: 0.568 D_B: 0.084 G_B: 0.340 cycle_B: 1.475 idt_B: 0.351 \n",
            "(epoch: 84, iters: 189, time: 0.329, data: 0.002) D_A: 0.146 G_A: 0.122 cycle_A: 0.883 idt_A: 0.485 D_B: 0.177 G_B: 0.351 cycle_B: 1.306 idt_B: 0.324 \n",
            "End of epoch 84 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 72, time: 0.330, data: 0.002) D_A: 0.185 G_A: 0.200 cycle_A: 0.580 idt_A: 0.449 D_B: 0.139 G_B: 0.228 cycle_B: 1.431 idt_B: 0.224 \n",
            "(epoch: 85, iters: 172, time: 1.393, data: 0.002) D_A: 0.125 G_A: 0.203 cycle_A: 0.584 idt_A: 0.605 D_B: 0.177 G_B: 0.353 cycle_B: 1.541 idt_B: 0.144 \n",
            "saving the model at the end of epoch 85, iters 18445\n",
            "End of epoch 85 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 55, time: 0.330, data: 0.002) D_A: 0.381 G_A: 0.078 cycle_A: 0.291 idt_A: 0.422 D_B: 0.346 G_B: 0.249 cycle_B: 1.245 idt_B: 0.087 \n",
            "(epoch: 86, iters: 155, time: 0.330, data: 0.002) D_A: 0.226 G_A: 0.299 cycle_A: 0.756 idt_A: 0.322 D_B: 0.090 G_B: 0.420 cycle_B: 1.037 idt_B: 0.231 \n",
            "End of epoch 86 / 200 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 38, time: 0.331, data: 0.002) D_A: 0.185 G_A: 0.440 cycle_A: 0.739 idt_A: 0.698 D_B: 0.135 G_B: 0.602 cycle_B: 1.657 idt_B: 0.254 \n",
            "(epoch: 87, iters: 138, time: 1.525, data: 0.002) D_A: 0.280 G_A: 0.441 cycle_A: 0.338 idt_A: 0.333 D_B: 0.364 G_B: 0.126 cycle_B: 1.019 idt_B: 0.086 \n",
            "End of epoch 87 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 21, time: 0.330, data: 0.002) D_A: 0.208 G_A: 0.185 cycle_A: 0.798 idt_A: 0.621 D_B: 0.103 G_B: 0.384 cycle_B: 1.786 idt_B: 0.297 \n",
            "(epoch: 88, iters: 121, time: 0.331, data: 0.002) D_A: 0.166 G_A: 0.481 cycle_A: 1.366 idt_A: 0.567 D_B: 0.333 G_B: 0.507 cycle_B: 1.346 idt_B: 0.405 \n",
            "End of epoch 88 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 4, time: 0.331, data: 0.002) D_A: 0.209 G_A: 0.237 cycle_A: 0.545 idt_A: 0.485 D_B: 0.165 G_B: 0.340 cycle_B: 2.091 idt_B: 0.176 \n",
            "(epoch: 89, iters: 104, time: 1.432, data: 0.005) D_A: 0.131 G_A: 0.197 cycle_A: 0.292 idt_A: 0.437 D_B: 0.241 G_B: 0.261 cycle_B: 1.450 idt_B: 0.091 \n",
            "(epoch: 89, iters: 204, time: 0.331, data: 0.002) D_A: 0.232 G_A: 0.237 cycle_A: 0.466 idt_A: 0.480 D_B: 0.367 G_B: 0.869 cycle_B: 1.398 idt_B: 0.139 \n",
            "End of epoch 89 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 87, time: 0.330, data: 0.002) D_A: 0.067 G_A: 0.230 cycle_A: 0.232 idt_A: 0.456 D_B: 0.082 G_B: 1.256 cycle_B: 1.423 idt_B: 0.070 \n",
            "(epoch: 90, iters: 187, time: 0.331, data: 0.002) D_A: 0.210 G_A: 0.332 cycle_A: 0.401 idt_A: 0.709 D_B: 0.042 G_B: 0.563 cycle_B: 1.579 idt_B: 0.103 \n",
            "saving the model at the end of epoch 90, iters 19530\n",
            "End of epoch 90 / 200 \t Time Taken: 72 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 70, time: 1.514, data: 0.002) D_A: 0.200 G_A: 0.273 cycle_A: 1.006 idt_A: 0.511 D_B: 0.221 G_B: 0.647 cycle_B: 1.659 idt_B: 0.380 \n",
            "(epoch: 91, iters: 170, time: 0.330, data: 0.002) D_A: 0.277 G_A: 0.213 cycle_A: 0.487 idt_A: 0.504 D_B: 0.088 G_B: 0.269 cycle_B: 1.530 idt_B: 0.159 \n",
            "End of epoch 91 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 92, iters: 53, time: 0.331, data: 0.002) D_A: 0.274 G_A: 0.405 cycle_A: 0.503 idt_A: 0.650 D_B: 0.131 G_B: 0.309 cycle_B: 1.644 idt_B: 0.146 \n",
            "(epoch: 92, iters: 153, time: 0.330, data: 0.002) D_A: 0.064 G_A: 0.119 cycle_A: 0.654 idt_A: 0.328 D_B: 0.022 G_B: 0.773 cycle_B: 0.998 idt_B: 0.207 \n",
            "End of epoch 92 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 36, time: 1.514, data: 0.002) D_A: 0.267 G_A: 0.193 cycle_A: 0.623 idt_A: 0.414 D_B: 0.053 G_B: 0.564 cycle_B: 1.203 idt_B: 0.209 \n",
            "saving the latest model (epoch 93, total_iters 20000)\n",
            "(epoch: 93, iters: 136, time: 0.330, data: 0.002) D_A: 0.281 G_A: 0.158 cycle_A: 0.610 idt_A: 0.422 D_B: 0.084 G_B: 0.433 cycle_B: 1.249 idt_B: 0.190 \n",
            "End of epoch 93 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 19, time: 0.331, data: 0.002) D_A: 0.103 G_A: 0.311 cycle_A: 0.423 idt_A: 0.582 D_B: 0.107 G_B: 1.163 cycle_B: 1.529 idt_B: 0.154 \n",
            "(epoch: 94, iters: 119, time: 0.330, data: 0.002) D_A: 0.275 G_A: 0.172 cycle_A: 0.707 idt_A: 0.488 D_B: 0.011 G_B: 1.178 cycle_B: 1.257 idt_B: 0.212 \n",
            "End of epoch 94 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 2, time: 1.589, data: 0.002) D_A: 0.288 G_A: 0.145 cycle_A: 0.274 idt_A: 0.423 D_B: 0.022 G_B: 0.302 cycle_B: 1.216 idt_B: 0.078 \n",
            "(epoch: 95, iters: 102, time: 0.330, data: 0.000) D_A: 0.286 G_A: 0.112 cycle_A: 0.838 idt_A: 0.336 D_B: 0.008 G_B: 0.947 cycle_B: 0.950 idt_B: 0.308 \n",
            "(epoch: 95, iters: 202, time: 0.330, data: 0.002) D_A: 0.193 G_A: 0.467 cycle_A: 0.632 idt_A: 0.373 D_B: 0.015 G_B: 0.808 cycle_B: 0.963 idt_B: 0.257 \n",
            "saving the model at the end of epoch 95, iters 20615\n",
            "End of epoch 95 / 200 \t Time Taken: 73 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 85, time: 0.332, data: 0.002) D_A: 0.270 G_A: 0.221 cycle_A: 0.267 idt_A: 0.519 D_B: 0.199 G_B: 0.212 cycle_B: 1.291 idt_B: 0.078 \n",
            "(epoch: 96, iters: 185, time: 1.596, data: 0.002) D_A: 0.124 G_A: 0.254 cycle_A: 0.797 idt_A: 0.602 D_B: 0.287 G_B: 0.324 cycle_B: 1.676 idt_B: 0.249 \n",
            "End of epoch 96 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 68, time: 0.331, data: 0.002) D_A: 0.181 G_A: 0.454 cycle_A: 0.355 idt_A: 0.499 D_B: 0.051 G_B: 0.611 cycle_B: 1.491 idt_B: 0.105 \n",
            "(epoch: 97, iters: 168, time: 0.331, data: 0.002) D_A: 0.337 G_A: 0.218 cycle_A: 0.278 idt_A: 0.361 D_B: 0.102 G_B: 0.918 cycle_B: 0.988 idt_B: 0.095 \n",
            "End of epoch 97 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 51, time: 0.331, data: 0.002) D_A: 0.263 G_A: 0.261 cycle_A: 0.537 idt_A: 0.429 D_B: 0.012 G_B: 1.183 cycle_B: 1.186 idt_B: 0.169 \n",
            "(epoch: 98, iters: 151, time: 1.522, data: 0.002) D_A: 0.143 G_A: 0.358 cycle_A: 0.341 idt_A: 0.452 D_B: 0.139 G_B: 0.587 cycle_B: 1.248 idt_B: 0.106 \n",
            "End of epoch 98 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 34, time: 0.331, data: 0.002) D_A: 0.457 G_A: 0.209 cycle_A: 0.259 idt_A: 0.432 D_B: 0.353 G_B: 0.177 cycle_B: 1.154 idt_B: 0.069 \n",
            "(epoch: 99, iters: 134, time: 0.330, data: 0.002) D_A: 0.335 G_A: 0.149 cycle_A: 0.382 idt_A: 0.438 D_B: 0.159 G_B: 0.278 cycle_B: 1.071 idt_B: 0.116 \n",
            "End of epoch 99 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0001980\n",
            "(epoch: 100, iters: 17, time: 0.331, data: 0.002) D_A: 0.169 G_A: 0.333 cycle_A: 0.371 idt_A: 0.417 D_B: 0.117 G_B: 0.229 cycle_B: 0.997 idt_B: 0.108 \n",
            "(epoch: 100, iters: 117, time: 1.601, data: 0.002) D_A: 0.109 G_A: 0.047 cycle_A: 0.346 idt_A: 0.782 D_B: 0.194 G_B: 0.436 cycle_B: 1.945 idt_B: 0.099 \n",
            "(epoch: 100, iters: 217, time: 0.332, data: 0.003) D_A: 0.136 G_A: 0.436 cycle_A: 0.580 idt_A: 0.331 D_B: 0.247 G_B: 0.272 cycle_B: 0.925 idt_B: 0.180 \n",
            "saving the model at the end of epoch 100, iters 21700\n",
            "End of epoch 100 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0001980 -> 0.0001960\n",
            "(epoch: 101, iters: 100, time: 0.331, data: 0.292) D_A: 0.218 G_A: 0.110 cycle_A: 0.913 idt_A: 0.376 D_B: 0.152 G_B: 0.313 cycle_B: 1.171 idt_B: 0.315 \n",
            "(epoch: 101, iters: 200, time: 0.331, data: 0.002) D_A: 0.194 G_A: 0.361 cycle_A: 0.628 idt_A: 0.527 D_B: 0.040 G_B: 0.998 cycle_B: 1.741 idt_B: 0.225 \n",
            "End of epoch 101 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001960 -> 0.0001941\n",
            "(epoch: 102, iters: 83, time: 1.588, data: 0.002) D_A: 0.320 G_A: 0.210 cycle_A: 0.732 idt_A: 0.408 D_B: 0.062 G_B: 0.857 cycle_B: 1.494 idt_B: 0.242 \n",
            "(epoch: 102, iters: 183, time: 0.332, data: 0.002) D_A: 0.210 G_A: 0.240 cycle_A: 0.363 idt_A: 0.456 D_B: 0.179 G_B: 0.207 cycle_B: 1.377 idt_B: 0.100 \n",
            "End of epoch 102 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001941 -> 0.0001921\n",
            "(epoch: 103, iters: 66, time: 0.331, data: 0.002) D_A: 0.155 G_A: 0.322 cycle_A: 0.757 idt_A: 0.533 D_B: 0.072 G_B: 0.435 cycle_B: 1.371 idt_B: 0.224 \n",
            "(epoch: 103, iters: 166, time: 0.331, data: 0.002) D_A: 0.162 G_A: 0.498 cycle_A: 0.522 idt_A: 0.469 D_B: 0.294 G_B: 0.250 cycle_B: 1.261 idt_B: 0.139 \n",
            "End of epoch 103 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001921 -> 0.0001901\n",
            "(epoch: 104, iters: 49, time: 1.604, data: 0.002) D_A: 0.094 G_A: 0.488 cycle_A: 0.540 idt_A: 0.380 D_B: 0.309 G_B: 0.174 cycle_B: 1.137 idt_B: 0.149 \n",
            "(epoch: 104, iters: 149, time: 0.329, data: 0.002) D_A: 0.147 G_A: 0.597 cycle_A: 0.153 idt_A: 0.450 D_B: 0.144 G_B: 0.365 cycle_B: 1.161 idt_B: 0.050 \n",
            "End of epoch 104 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001901 -> 0.0001881\n",
            "(epoch: 105, iters: 32, time: 0.331, data: 0.002) D_A: 0.147 G_A: 0.508 cycle_A: 0.304 idt_A: 0.366 D_B: 0.061 G_B: 0.501 cycle_B: 1.131 idt_B: 0.095 \n",
            "(epoch: 105, iters: 132, time: 0.330, data: 0.002) D_A: 0.428 G_A: 0.047 cycle_A: 0.671 idt_A: 0.358 D_B: 0.034 G_B: 0.831 cycle_B: 0.948 idt_B: 0.199 \n",
            "saving the model at the end of epoch 105, iters 22785\n",
            "End of epoch 105 / 200 \t Time Taken: 71 sec\n",
            "learning rate 0.0001881 -> 0.0001861\n",
            "(epoch: 106, iters: 15, time: 1.666, data: 0.002) D_A: 0.231 G_A: 0.578 cycle_A: 0.306 idt_A: 0.421 D_B: 0.388 G_B: 1.354 cycle_B: 1.351 idt_B: 0.088 \n",
            "(epoch: 106, iters: 115, time: 0.331, data: 0.002) D_A: 0.153 G_A: 0.256 cycle_A: 0.377 idt_A: 0.539 D_B: 0.009 G_B: 0.955 cycle_B: 0.999 idt_B: 0.113 \n",
            "(epoch: 106, iters: 215, time: 0.331, data: 0.002) D_A: 0.201 G_A: 0.481 cycle_A: 0.306 idt_A: 0.392 D_B: 0.027 G_B: 0.178 cycle_B: 1.234 idt_B: 0.083 \n",
            "End of epoch 106 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001861 -> 0.0001842\n",
            "(epoch: 107, iters: 98, time: 0.331, data: 0.002) D_A: 0.300 G_A: 0.322 cycle_A: 0.462 idt_A: 0.426 D_B: 0.052 G_B: 0.728 cycle_B: 1.242 idt_B: 0.137 \n",
            "(epoch: 107, iters: 198, time: 1.650, data: 0.002) D_A: 0.273 G_A: 0.125 cycle_A: 0.504 idt_A: 0.441 D_B: 0.152 G_B: 0.496 cycle_B: 1.469 idt_B: 0.145 \n",
            "End of epoch 107 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001842 -> 0.0001822\n",
            "(epoch: 108, iters: 81, time: 0.331, data: 0.002) D_A: 0.085 G_A: 0.281 cycle_A: 0.419 idt_A: 0.656 D_B: 0.233 G_B: 0.148 cycle_B: 1.201 idt_B: 0.143 \n",
            "(epoch: 108, iters: 181, time: 0.332, data: 0.002) D_A: 0.304 G_A: 0.105 cycle_A: 0.636 idt_A: 0.313 D_B: 0.170 G_B: 0.129 cycle_B: 1.013 idt_B: 0.183 \n",
            "End of epoch 108 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001822 -> 0.0001802\n",
            "(epoch: 109, iters: 64, time: 0.331, data: 0.002) D_A: 0.250 G_A: 0.278 cycle_A: 0.676 idt_A: 0.454 D_B: 0.047 G_B: 0.564 cycle_B: 1.341 idt_B: 0.225 \n",
            "(epoch: 109, iters: 164, time: 1.664, data: 0.002) D_A: 0.148 G_A: 0.138 cycle_A: 1.255 idt_A: 0.357 D_B: 0.029 G_B: 0.855 cycle_B: 0.841 idt_B: 0.536 \n",
            "End of epoch 109 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001802 -> 0.0001782\n",
            "(epoch: 110, iters: 47, time: 0.331, data: 0.002) D_A: 0.150 G_A: 0.467 cycle_A: 0.402 idt_A: 0.359 D_B: 0.031 G_B: 0.634 cycle_B: 0.983 idt_B: 0.106 \n",
            "(epoch: 110, iters: 147, time: 0.331, data: 0.002) D_A: 0.094 G_A: 0.396 cycle_A: 0.496 idt_A: 0.508 D_B: 0.202 G_B: 0.200 cycle_B: 1.399 idt_B: 0.155 \n",
            "saving the model at the end of epoch 110, iters 23870\n",
            "End of epoch 110 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001782 -> 0.0001762\n",
            "(epoch: 111, iters: 30, time: 0.330, data: 0.002) D_A: 0.088 G_A: 0.509 cycle_A: 0.669 idt_A: 0.369 D_B: 0.115 G_B: 0.299 cycle_B: 1.222 idt_B: 0.225 \n",
            "(epoch: 111, iters: 130, time: 1.723, data: 0.003) D_A: 0.127 G_A: 0.152 cycle_A: 0.936 idt_A: 0.480 D_B: 0.014 G_B: 0.842 cycle_B: 1.094 idt_B: 0.273 \n",
            "End of epoch 111 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001762 -> 0.0001743\n",
            "(epoch: 112, iters: 13, time: 0.331, data: 0.002) D_A: 0.367 G_A: 0.138 cycle_A: 0.586 idt_A: 0.328 D_B: 0.120 G_B: 0.544 cycle_B: 1.119 idt_B: 0.181 \n",
            "(epoch: 112, iters: 113, time: 0.329, data: 0.002) D_A: 0.240 G_A: 0.415 cycle_A: 0.250 idt_A: 0.465 D_B: 0.350 G_B: 1.624 cycle_B: 1.384 idt_B: 0.079 \n",
            "(epoch: 112, iters: 213, time: 0.331, data: 0.002) D_A: 0.249 G_A: 0.380 cycle_A: 0.355 idt_A: 0.459 D_B: 0.051 G_B: 0.458 cycle_B: 1.259 idt_B: 0.114 \n",
            "End of epoch 112 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001743 -> 0.0001723\n",
            "(epoch: 113, iters: 96, time: 1.693, data: 0.002) D_A: 0.342 G_A: 0.052 cycle_A: 0.702 idt_A: 0.396 D_B: 0.013 G_B: 0.787 cycle_B: 1.222 idt_B: 0.221 \n",
            "(epoch: 113, iters: 196, time: 0.331, data: 0.002) D_A: 0.229 G_A: 0.358 cycle_A: 0.516 idt_A: 0.540 D_B: 0.071 G_B: 0.434 cycle_B: 1.432 idt_B: 0.173 \n",
            "End of epoch 113 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001723 -> 0.0001703\n",
            "(epoch: 114, iters: 79, time: 0.331, data: 0.002) D_A: 0.272 G_A: 0.167 cycle_A: 0.466 idt_A: 0.446 D_B: 0.274 G_B: 0.311 cycle_B: 1.196 idt_B: 0.129 \n",
            "(epoch: 114, iters: 179, time: 0.330, data: 0.002) D_A: 0.235 G_A: 0.556 cycle_A: 0.663 idt_A: 0.473 D_B: 0.171 G_B: 0.262 cycle_B: 1.330 idt_B: 0.213 \n",
            "End of epoch 114 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001703 -> 0.0001683\n",
            "(epoch: 115, iters: 62, time: 1.714, data: 0.002) D_A: 0.304 G_A: 0.140 cycle_A: 0.633 idt_A: 0.432 D_B: 0.123 G_B: 0.408 cycle_B: 1.235 idt_B: 0.200 \n",
            "(epoch: 115, iters: 162, time: 0.331, data: 0.002) D_A: 0.282 G_A: 0.259 cycle_A: 0.308 idt_A: 0.398 D_B: 0.118 G_B: 0.337 cycle_B: 1.295 idt_B: 0.100 \n",
            "saving the model at the end of epoch 115, iters 24955\n",
            "End of epoch 115 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "(epoch: 116, iters: 45, time: 0.331, data: 0.002) D_A: 0.279 G_A: 0.302 cycle_A: 0.490 idt_A: 0.358 D_B: 0.394 G_B: 0.023 cycle_B: 1.251 idt_B: 0.168 \n",
            "saving the latest model (epoch 116, total_iters 25000)\n",
            "(epoch: 116, iters: 145, time: 0.331, data: 0.002) D_A: 0.200 G_A: 0.698 cycle_A: 0.619 idt_A: 0.328 D_B: 0.251 G_B: 0.117 cycle_B: 1.069 idt_B: 0.183 \n",
            "End of epoch 116 / 200 \t Time Taken: 71 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "(epoch: 117, iters: 28, time: 1.743, data: 0.002) D_A: 0.280 G_A: 0.271 cycle_A: 0.415 idt_A: 0.444 D_B: 0.245 G_B: 0.293 cycle_B: 1.229 idt_B: 0.121 \n",
            "(epoch: 117, iters: 128, time: 0.330, data: 0.002) D_A: 0.246 G_A: 0.287 cycle_A: 0.579 idt_A: 0.281 D_B: 0.346 G_B: 0.387 cycle_B: 0.936 idt_B: 0.161 \n",
            "End of epoch 117 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "(epoch: 118, iters: 11, time: 0.330, data: 0.002) D_A: 0.161 G_A: 0.466 cycle_A: 0.264 idt_A: 0.274 D_B: 0.082 G_B: 0.850 cycle_B: 1.081 idt_B: 0.079 \n",
            "(epoch: 118, iters: 111, time: 0.331, data: 0.002) D_A: 0.192 G_A: 0.520 cycle_A: 0.413 idt_A: 0.276 D_B: 0.016 G_B: 0.844 cycle_B: 0.961 idt_B: 0.135 \n",
            "(epoch: 118, iters: 211, time: 1.760, data: 0.002) D_A: 0.109 G_A: 0.277 cycle_A: 1.009 idt_A: 0.446 D_B: 0.120 G_B: 0.861 cycle_B: 1.126 idt_B: 0.372 \n",
            "End of epoch 118 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "(epoch: 119, iters: 94, time: 0.331, data: 0.002) D_A: 0.210 G_A: 0.393 cycle_A: 0.605 idt_A: 0.556 D_B: 0.011 G_B: 0.831 cycle_B: 1.100 idt_B: 0.182 \n",
            "(epoch: 119, iters: 194, time: 0.331, data: 0.002) D_A: 0.141 G_A: 0.211 cycle_A: 0.400 idt_A: 0.649 D_B: 0.156 G_B: 0.452 cycle_B: 1.689 idt_B: 0.133 \n",
            "End of epoch 119 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "(epoch: 120, iters: 77, time: 0.330, data: 0.002) D_A: 0.271 G_A: 0.328 cycle_A: 0.879 idt_A: 0.543 D_B: 0.306 G_B: 0.167 cycle_B: 1.464 idt_B: 0.253 \n",
            "(epoch: 120, iters: 177, time: 1.757, data: 0.002) D_A: 0.101 G_A: 0.213 cycle_A: 0.239 idt_A: 0.444 D_B: 0.037 G_B: 0.829 cycle_B: 1.356 idt_B: 0.080 \n",
            "saving the model at the end of epoch 120, iters 26040\n",
            "End of epoch 120 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "(epoch: 121, iters: 60, time: 0.332, data: 0.002) D_A: 0.330 G_A: 0.148 cycle_A: 0.270 idt_A: 0.676 D_B: 0.015 G_B: 0.577 cycle_B: 1.267 idt_B: 0.080 \n",
            "(epoch: 121, iters: 160, time: 0.331, data: 0.002) D_A: 0.263 G_A: 0.150 cycle_A: 0.473 idt_A: 0.259 D_B: 0.017 G_B: 0.764 cycle_B: 0.869 idt_B: 0.135 \n",
            "End of epoch 121 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "(epoch: 122, iters: 43, time: 0.331, data: 0.002) D_A: 0.235 G_A: 0.235 cycle_A: 0.779 idt_A: 0.355 D_B: 0.089 G_B: 0.417 cycle_B: 1.223 idt_B: 0.293 \n",
            "(epoch: 122, iters: 143, time: 1.656, data: 0.002) D_A: 0.280 G_A: 0.173 cycle_A: 0.213 idt_A: 0.608 D_B: 0.192 G_B: 0.403 cycle_B: 1.441 idt_B: 0.068 \n",
            "End of epoch 122 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "(epoch: 123, iters: 26, time: 0.332, data: 0.002) D_A: 0.299 G_A: 0.312 cycle_A: 0.551 idt_A: 0.423 D_B: 0.366 G_B: 0.152 cycle_B: 1.322 idt_B: 0.119 \n",
            "(epoch: 123, iters: 126, time: 0.331, data: 0.002) D_A: 0.123 G_A: 0.391 cycle_A: 0.643 idt_A: 0.646 D_B: 0.016 G_B: 0.929 cycle_B: 1.763 idt_B: 0.161 \n",
            "End of epoch 123 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "(epoch: 124, iters: 9, time: 0.333, data: 0.002) D_A: 0.430 G_A: 0.066 cycle_A: 0.734 idt_A: 0.355 D_B: 0.011 G_B: 0.936 cycle_B: 1.259 idt_B: 0.277 \n",
            "(epoch: 124, iters: 109, time: 1.713, data: 0.002) D_A: 0.279 G_A: 0.101 cycle_A: 0.287 idt_A: 0.410 D_B: 0.232 G_B: 0.503 cycle_B: 1.141 idt_B: 0.091 \n",
            "(epoch: 124, iters: 209, time: 0.333, data: 0.002) D_A: 0.340 G_A: 0.170 cycle_A: 0.328 idt_A: 0.421 D_B: 0.029 G_B: 0.648 cycle_B: 1.161 idt_B: 0.107 \n",
            "End of epoch 124 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "(epoch: 125, iters: 92, time: 0.332, data: 0.002) D_A: 0.315 G_A: 0.272 cycle_A: 0.327 idt_A: 0.553 D_B: 0.008 G_B: 0.906 cycle_B: 1.425 idt_B: 0.070 \n",
            "(epoch: 125, iters: 192, time: 0.333, data: 0.002) D_A: 0.326 G_A: 0.126 cycle_A: 0.415 idt_A: 0.358 D_B: 0.254 G_B: 0.491 cycle_B: 1.091 idt_B: 0.117 \n",
            "saving the model at the end of epoch 125, iters 27125\n",
            "End of epoch 125 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "(epoch: 126, iters: 75, time: 1.780, data: 0.002) D_A: 0.318 G_A: 0.223 cycle_A: 0.229 idt_A: 0.426 D_B: 0.258 G_B: 0.216 cycle_B: 1.199 idt_B: 0.071 \n",
            "(epoch: 126, iters: 175, time: 0.332, data: 0.002) D_A: 0.234 G_A: 0.383 cycle_A: 0.387 idt_A: 0.311 D_B: 0.389 G_B: 0.212 cycle_B: 1.048 idt_B: 0.123 \n",
            "End of epoch 126 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "(epoch: 127, iters: 58, time: 0.332, data: 0.002) D_A: 0.259 G_A: 0.168 cycle_A: 0.555 idt_A: 0.261 D_B: 0.178 G_B: 0.327 cycle_B: 0.925 idt_B: 0.195 \n",
            "(epoch: 127, iters: 158, time: 0.332, data: 0.002) D_A: 0.149 G_A: 0.379 cycle_A: 0.779 idt_A: 0.362 D_B: 0.060 G_B: 1.035 cycle_B: 0.996 idt_B: 0.251 \n",
            "End of epoch 127 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "(epoch: 128, iters: 41, time: 1.812, data: 0.002) D_A: 0.132 G_A: 0.505 cycle_A: 0.445 idt_A: 0.287 D_B: 0.215 G_B: 0.245 cycle_B: 0.748 idt_B: 0.157 \n",
            "(epoch: 128, iters: 141, time: 0.331, data: 0.002) D_A: 0.161 G_A: 0.097 cycle_A: 0.373 idt_A: 0.275 D_B: 0.299 G_B: 0.148 cycle_B: 0.815 idt_B: 0.114 \n",
            "End of epoch 128 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "(epoch: 129, iters: 24, time: 0.332, data: 0.002) D_A: 0.240 G_A: 0.162 cycle_A: 0.365 idt_A: 0.303 D_B: 0.090 G_B: 1.116 cycle_B: 0.955 idt_B: 0.118 \n",
            "(epoch: 129, iters: 124, time: 0.333, data: 0.002) D_A: 0.110 G_A: 0.498 cycle_A: 0.345 idt_A: 0.279 D_B: 0.017 G_B: 0.973 cycle_B: 0.756 idt_B: 0.106 \n",
            "End of epoch 129 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001406 -> 0.0001386\n",
            "(epoch: 130, iters: 7, time: 1.840, data: 0.002) D_A: 0.067 G_A: 0.223 cycle_A: 0.446 idt_A: 0.283 D_B: 0.009 G_B: 1.154 cycle_B: 0.781 idt_B: 0.159 \n",
            "(epoch: 130, iters: 107, time: 0.332, data: 0.000) D_A: 0.313 G_A: 0.258 cycle_A: 0.426 idt_A: 0.301 D_B: 0.021 G_B: 0.731 cycle_B: 1.008 idt_B: 0.128 \n",
            "(epoch: 130, iters: 207, time: 0.332, data: 0.002) D_A: 0.147 G_A: 0.350 cycle_A: 0.233 idt_A: 0.292 D_B: 0.050 G_B: 0.677 cycle_B: 0.957 idt_B: 0.077 \n",
            "saving the model at the end of epoch 130, iters 28210\n",
            "End of epoch 130 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0001386 -> 0.0001366\n",
            "(epoch: 131, iters: 90, time: 0.332, data: 0.002) D_A: 0.122 G_A: 0.362 cycle_A: 0.394 idt_A: 0.465 D_B: 0.048 G_B: 0.658 cycle_B: 1.248 idt_B: 0.120 \n",
            "(epoch: 131, iters: 190, time: 1.784, data: 0.002) D_A: 0.168 G_A: 0.221 cycle_A: 0.315 idt_A: 0.422 D_B: 0.128 G_B: 0.276 cycle_B: 1.309 idt_B: 0.107 \n",
            "End of epoch 131 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001366 -> 0.0001347\n",
            "(epoch: 132, iters: 73, time: 0.332, data: 0.001) D_A: 0.184 G_A: 0.377 cycle_A: 0.649 idt_A: 0.422 D_B: 0.275 G_B: 0.092 cycle_B: 1.618 idt_B: 0.185 \n",
            "(epoch: 132, iters: 173, time: 0.331, data: 0.002) D_A: 0.186 G_A: 0.403 cycle_A: 0.287 idt_A: 0.345 D_B: 0.134 G_B: 0.293 cycle_B: 1.071 idt_B: 0.088 \n",
            "End of epoch 132 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001347 -> 0.0001327\n",
            "(epoch: 133, iters: 56, time: 0.332, data: 0.002) D_A: 0.206 G_A: 0.428 cycle_A: 0.758 idt_A: 0.378 D_B: 0.146 G_B: 0.231 cycle_B: 0.936 idt_B: 0.257 \n",
            "(epoch: 133, iters: 156, time: 1.821, data: 0.002) D_A: 0.200 G_A: 0.362 cycle_A: 0.493 idt_A: 0.366 D_B: 0.197 G_B: 0.174 cycle_B: 0.851 idt_B: 0.151 \n",
            "End of epoch 133 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001327 -> 0.0001307\n",
            "(epoch: 134, iters: 39, time: 0.332, data: 0.002) D_A: 0.180 G_A: 0.305 cycle_A: 0.416 idt_A: 0.491 D_B: 0.121 G_B: 0.347 cycle_B: 1.310 idt_B: 0.133 \n",
            "(epoch: 134, iters: 139, time: 0.332, data: 0.001) D_A: 0.163 G_A: 0.369 cycle_A: 0.406 idt_A: 0.412 D_B: 0.139 G_B: 0.198 cycle_B: 1.249 idt_B: 0.102 \n",
            "End of epoch 134 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001307 -> 0.0001287\n",
            "(epoch: 135, iters: 22, time: 0.333, data: 0.002) D_A: 0.227 G_A: 0.174 cycle_A: 0.540 idt_A: 0.407 D_B: 0.088 G_B: 0.382 cycle_B: 1.143 idt_B: 0.156 \n",
            "(epoch: 135, iters: 122, time: 1.893, data: 0.002) D_A: 0.228 G_A: 0.272 cycle_A: 0.569 idt_A: 0.289 D_B: 0.279 G_B: 0.112 cycle_B: 1.490 idt_B: 0.170 \n",
            "saving the model at the end of epoch 135, iters 29295\n",
            "End of epoch 135 / 200 \t Time Taken: 73 sec\n",
            "learning rate 0.0001287 -> 0.0001267\n",
            "(epoch: 136, iters: 5, time: 0.332, data: 0.002) D_A: 0.304 G_A: 0.250 cycle_A: 0.234 idt_A: 0.416 D_B: 0.335 G_B: 0.310 cycle_B: 1.187 idt_B: 0.061 \n",
            "(epoch: 136, iters: 105, time: 0.332, data: 0.003) D_A: 0.230 G_A: 0.295 cycle_A: 0.514 idt_A: 0.377 D_B: 0.056 G_B: 0.148 cycle_B: 0.947 idt_B: 0.177 \n",
            "(epoch: 136, iters: 205, time: 0.333, data: 0.002) D_A: 0.118 G_A: 0.543 cycle_A: 1.072 idt_A: 0.529 D_B: 0.029 G_B: 0.745 cycle_B: 1.025 idt_B: 0.445 \n",
            "End of epoch 136 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001267 -> 0.0001248\n",
            "(epoch: 137, iters: 88, time: 1.856, data: 0.002) D_A: 0.155 G_A: 0.313 cycle_A: 0.701 idt_A: 0.395 D_B: 0.008 G_B: 0.898 cycle_B: 1.310 idt_B: 0.186 \n",
            "(epoch: 137, iters: 188, time: 0.333, data: 0.002) D_A: 0.209 G_A: 0.381 cycle_A: 0.491 idt_A: 0.558 D_B: 0.019 G_B: 0.817 cycle_B: 1.366 idt_B: 0.137 \n",
            "End of epoch 137 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001248 -> 0.0001228\n",
            "(epoch: 138, iters: 71, time: 0.332, data: 0.002) D_A: 0.319 G_A: 0.379 cycle_A: 0.803 idt_A: 0.321 D_B: 0.005 G_B: 1.100 cycle_B: 1.125 idt_B: 0.291 \n",
            "(epoch: 138, iters: 171, time: 0.332, data: 0.002) D_A: 0.334 G_A: 0.179 cycle_A: 0.581 idt_A: 0.360 D_B: 0.004 G_B: 1.021 cycle_B: 1.134 idt_B: 0.164 \n",
            "End of epoch 138 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001228 -> 0.0001208\n",
            "(epoch: 139, iters: 54, time: 1.910, data: 0.002) D_A: 0.036 G_A: 0.144 cycle_A: 0.222 idt_A: 0.320 D_B: 0.004 G_B: 1.059 cycle_B: 0.741 idt_B: 0.072 \n",
            "saving the latest model (epoch 139, total_iters 30000)\n",
            "(epoch: 139, iters: 154, time: 0.332, data: 0.002) D_A: 0.057 G_A: 0.195 cycle_A: 0.232 idt_A: 0.614 D_B: 0.003 G_B: 0.954 cycle_B: 1.538 idt_B: 0.078 \n",
            "End of epoch 139 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0001208 -> 0.0001188\n",
            "(epoch: 140, iters: 37, time: 0.332, data: 0.002) D_A: 0.110 G_A: 0.342 cycle_A: 0.605 idt_A: 0.362 D_B: 0.008 G_B: 1.160 cycle_B: 1.270 idt_B: 0.194 \n",
            "(epoch: 140, iters: 137, time: 0.333, data: 0.002) D_A: 0.135 G_A: 0.058 cycle_A: 0.375 idt_A: 0.202 D_B: 0.003 G_B: 1.019 cycle_B: 0.656 idt_B: 0.124 \n",
            "saving the model at the end of epoch 140, iters 30380\n",
            "End of epoch 140 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001188 -> 0.0001168\n",
            "(epoch: 141, iters: 20, time: 2.292, data: 0.002) D_A: 0.146 G_A: 0.346 cycle_A: 0.317 idt_A: 0.311 D_B: 0.004 G_B: 0.925 cycle_B: 0.836 idt_B: 0.091 \n",
            "(epoch: 141, iters: 120, time: 0.332, data: 0.001) D_A: 0.186 G_A: 0.302 cycle_A: 0.170 idt_A: 0.426 D_B: 0.003 G_B: 0.931 cycle_B: 1.139 idt_B: 0.048 \n",
            "End of epoch 141 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0001168 -> 0.0001149\n",
            "(epoch: 142, iters: 3, time: 0.333, data: 0.002) D_A: 0.059 G_A: 0.216 cycle_A: 0.221 idt_A: 0.301 D_B: 0.003 G_B: 0.954 cycle_B: 0.971 idt_B: 0.064 \n",
            "(epoch: 142, iters: 103, time: 0.332, data: 0.000) D_A: 0.103 G_A: 0.330 cycle_A: 0.233 idt_A: 0.417 D_B: 0.002 G_B: 1.075 cycle_B: 1.543 idt_B: 0.067 \n",
            "(epoch: 142, iters: 203, time: 1.907, data: 0.002) D_A: 0.128 G_A: 0.180 cycle_A: 0.298 idt_A: 0.440 D_B: 0.003 G_B: 1.023 cycle_B: 1.297 idt_B: 0.099 \n",
            "End of epoch 142 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001149 -> 0.0001129\n",
            "(epoch: 143, iters: 86, time: 0.332, data: 0.001) D_A: 0.186 G_A: 0.276 cycle_A: 0.612 idt_A: 0.353 D_B: 0.366 G_B: 0.143 cycle_B: 0.778 idt_B: 0.195 \n",
            "(epoch: 143, iters: 186, time: 0.333, data: 0.002) D_A: 0.226 G_A: 0.177 cycle_A: 0.492 idt_A: 0.462 D_B: 0.006 G_B: 0.924 cycle_B: 1.219 idt_B: 0.154 \n",
            "End of epoch 143 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001129 -> 0.0001109\n",
            "(epoch: 144, iters: 69, time: 0.333, data: 0.002) D_A: 0.399 G_A: 0.307 cycle_A: 0.359 idt_A: 0.343 D_B: 0.054 G_B: 0.280 cycle_B: 1.028 idt_B: 0.105 \n",
            "(epoch: 144, iters: 169, time: 1.868, data: 0.002) D_A: 0.151 G_A: 0.211 cycle_A: 0.306 idt_A: 0.403 D_B: 0.110 G_B: 0.389 cycle_B: 0.982 idt_B: 0.081 \n",
            "End of epoch 144 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001109 -> 0.0001089\n",
            "(epoch: 145, iters: 52, time: 0.331, data: 0.002) D_A: 0.260 G_A: 0.277 cycle_A: 0.421 idt_A: 0.469 D_B: 0.224 G_B: 0.142 cycle_B: 1.337 idt_B: 0.123 \n",
            "(epoch: 145, iters: 152, time: 0.332, data: 0.002) D_A: 0.185 G_A: 0.223 cycle_A: 0.508 idt_A: 0.310 D_B: 0.007 G_B: 0.229 cycle_B: 1.183 idt_B: 0.157 \n",
            "saving the model at the end of epoch 145, iters 31465\n",
            "End of epoch 145 / 200 \t Time Taken: 71 sec\n",
            "learning rate 0.0001089 -> 0.0001069\n",
            "(epoch: 146, iters: 35, time: 0.332, data: 0.002) D_A: 0.264 G_A: 0.306 cycle_A: 0.264 idt_A: 0.518 D_B: 0.229 G_B: 0.248 cycle_B: 1.353 idt_B: 0.089 \n",
            "(epoch: 146, iters: 135, time: 1.976, data: 0.002) D_A: 0.188 G_A: 0.302 cycle_A: 0.359 idt_A: 0.253 D_B: 0.182 G_B: 0.125 cycle_B: 0.916 idt_B: 0.106 \n",
            "End of epoch 146 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0001069 -> 0.0001050\n",
            "(epoch: 147, iters: 18, time: 0.331, data: 0.002) D_A: 0.213 G_A: 0.275 cycle_A: 0.321 idt_A: 0.371 D_B: 0.084 G_B: 0.305 cycle_B: 0.959 idt_B: 0.100 \n",
            "(epoch: 147, iters: 118, time: 0.332, data: 0.001) D_A: 0.128 G_A: 0.387 cycle_A: 0.263 idt_A: 0.380 D_B: 0.058 G_B: 0.677 cycle_B: 1.271 idt_B: 0.086 \n",
            "End of epoch 147 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001050 -> 0.0001030\n",
            "(epoch: 148, iters: 1, time: 0.385, data: 0.002) D_A: 0.167 G_A: 0.303 cycle_A: 0.223 idt_A: 0.269 D_B: 0.021 G_B: 0.140 cycle_B: 0.856 idt_B: 0.057 \n",
            "(epoch: 148, iters: 101, time: 1.940, data: 0.006) D_A: 0.305 G_A: 0.609 cycle_A: 0.368 idt_A: 0.273 D_B: 0.041 G_B: 0.806 cycle_B: 0.844 idt_B: 0.115 \n",
            "(epoch: 148, iters: 201, time: 0.329, data: 0.002) D_A: 0.184 G_A: 0.235 cycle_A: 0.228 idt_A: 0.325 D_B: 0.006 G_B: 1.026 cycle_B: 0.962 idt_B: 0.079 \n",
            "End of epoch 148 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0001030 -> 0.0001010\n",
            "(epoch: 149, iters: 84, time: 0.332, data: 0.002) D_A: 0.298 G_A: 0.197 cycle_A: 0.797 idt_A: 0.224 D_B: 0.020 G_B: 0.801 cycle_B: 0.647 idt_B: 0.304 \n",
            "(epoch: 149, iters: 184, time: 0.332, data: 0.002) D_A: 0.126 G_A: 0.230 cycle_A: 0.398 idt_A: 0.429 D_B: 0.133 G_B: 0.259 cycle_B: 1.265 idt_B: 0.125 \n",
            "End of epoch 149 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0001010 -> 0.0000990\n",
            "(epoch: 150, iters: 67, time: 1.992, data: 0.002) D_A: 0.120 G_A: 0.480 cycle_A: 0.843 idt_A: 0.400 D_B: 0.135 G_B: 0.303 cycle_B: 0.960 idt_B: 0.298 \n",
            "(epoch: 150, iters: 167, time: 0.332, data: 0.002) D_A: 0.224 G_A: 0.538 cycle_A: 0.409 idt_A: 0.442 D_B: 0.241 G_B: 0.606 cycle_B: 1.339 idt_B: 0.135 \n",
            "saving the model at the end of epoch 150, iters 32550\n",
            "End of epoch 150 / 200 \t Time Taken: 73 sec\n",
            "learning rate 0.0000990 -> 0.0000970\n",
            "(epoch: 151, iters: 50, time: 0.333, data: 0.002) D_A: 0.125 G_A: 0.227 cycle_A: 0.527 idt_A: 0.281 D_B: 0.068 G_B: 0.431 cycle_B: 0.823 idt_B: 0.199 \n",
            "(epoch: 151, iters: 150, time: 0.331, data: 0.002) D_A: 0.233 G_A: 0.677 cycle_A: 0.245 idt_A: 0.410 D_B: 0.210 G_B: 0.240 cycle_B: 1.269 idt_B: 0.070 \n",
            "End of epoch 151 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000970 -> 0.0000950\n",
            "(epoch: 152, iters: 33, time: 1.990, data: 0.002) D_A: 0.155 G_A: 0.354 cycle_A: 0.492 idt_A: 0.274 D_B: 0.013 G_B: 0.484 cycle_B: 0.977 idt_B: 0.177 \n",
            "(epoch: 152, iters: 133, time: 0.332, data: 0.002) D_A: 0.246 G_A: 0.230 cycle_A: 0.300 idt_A: 0.301 D_B: 0.292 G_B: 0.552 cycle_B: 0.879 idt_B: 0.088 \n",
            "End of epoch 152 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0000950 -> 0.0000931\n",
            "(epoch: 153, iters: 16, time: 0.332, data: 0.002) D_A: 0.123 G_A: 0.294 cycle_A: 0.333 idt_A: 0.184 D_B: 0.018 G_B: 0.981 cycle_B: 0.494 idt_B: 0.105 \n",
            "(epoch: 153, iters: 116, time: 0.332, data: 0.002) D_A: 0.159 G_A: 0.264 cycle_A: 0.481 idt_A: 0.367 D_B: 0.009 G_B: 0.128 cycle_B: 1.253 idt_B: 0.146 \n",
            "(epoch: 153, iters: 216, time: 2.005, data: 0.002) D_A: 0.120 G_A: 0.523 cycle_A: 0.695 idt_A: 0.314 D_B: 0.019 G_B: 0.888 cycle_B: 0.906 idt_B: 0.236 \n",
            "End of epoch 153 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0000931 -> 0.0000911\n",
            "(epoch: 154, iters: 99, time: 0.331, data: 0.002) D_A: 0.128 G_A: 0.342 cycle_A: 0.337 idt_A: 0.188 D_B: 0.005 G_B: 0.927 cycle_B: 0.727 idt_B: 0.112 \n",
            "(epoch: 154, iters: 199, time: 0.332, data: 0.002) D_A: 0.128 G_A: 0.228 cycle_A: 0.408 idt_A: 0.254 D_B: 0.014 G_B: 1.029 cycle_B: 0.785 idt_B: 0.138 \n",
            "End of epoch 154 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000911 -> 0.0000891\n",
            "(epoch: 155, iters: 82, time: 0.332, data: 0.002) D_A: 0.101 G_A: 0.487 cycle_A: 0.277 idt_A: 0.229 D_B: 0.266 G_B: 0.116 cycle_B: 0.770 idt_B: 0.088 \n",
            "(epoch: 155, iters: 182, time: 2.022, data: 0.002) D_A: 0.104 G_A: 0.182 cycle_A: 0.521 idt_A: 0.375 D_B: 0.010 G_B: 0.840 cycle_B: 1.104 idt_B: 0.180 \n",
            "saving the model at the end of epoch 155, iters 33635\n",
            "End of epoch 155 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000891 -> 0.0000871\n",
            "(epoch: 156, iters: 65, time: 0.332, data: 0.002) D_A: 0.122 G_A: 0.600 cycle_A: 0.350 idt_A: 0.234 D_B: 0.061 G_B: 0.477 cycle_B: 0.691 idt_B: 0.113 \n",
            "(epoch: 156, iters: 165, time: 0.331, data: 0.002) D_A: 0.055 G_A: 0.083 cycle_A: 0.552 idt_A: 0.303 D_B: 0.161 G_B: 1.118 cycle_B: 0.729 idt_B: 0.186 \n",
            "End of epoch 156 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000871 -> 0.0000851\n",
            "(epoch: 157, iters: 48, time: 0.333, data: 0.001) D_A: 0.121 G_A: 0.306 cycle_A: 0.246 idt_A: 0.301 D_B: 0.017 G_B: 0.998 cycle_B: 0.954 idt_B: 0.076 \n",
            "(epoch: 157, iters: 148, time: 1.978, data: 0.002) D_A: 0.244 G_A: 0.426 cycle_A: 0.721 idt_A: 0.373 D_B: 0.060 G_B: 0.088 cycle_B: 1.191 idt_B: 0.212 \n",
            "End of epoch 157 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0000851 -> 0.0000832\n",
            "(epoch: 158, iters: 31, time: 0.332, data: 0.002) D_A: 0.243 G_A: 0.270 cycle_A: 0.237 idt_A: 0.393 D_B: 0.110 G_B: 0.345 cycle_B: 1.251 idt_B: 0.066 \n",
            "(epoch: 158, iters: 131, time: 0.332, data: 0.002) D_A: 0.037 G_A: 0.211 cycle_A: 0.504 idt_A: 0.230 D_B: 0.210 G_B: 0.081 cycle_B: 0.677 idt_B: 0.158 \n",
            "End of epoch 158 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000832 -> 0.0000812\n",
            "(epoch: 159, iters: 14, time: 0.332, data: 0.002) D_A: 0.308 G_A: 0.097 cycle_A: 0.313 idt_A: 0.208 D_B: 0.117 G_B: 0.478 cycle_B: 0.512 idt_B: 0.111 \n",
            "(epoch: 159, iters: 114, time: 2.061, data: 0.002) D_A: 0.142 G_A: 0.299 cycle_A: 0.366 idt_A: 0.349 D_B: 0.294 G_B: 0.265 cycle_B: 1.029 idt_B: 0.106 \n",
            "(epoch: 159, iters: 214, time: 0.332, data: 0.002) D_A: 0.196 G_A: 0.300 cycle_A: 0.193 idt_A: 0.343 D_B: 0.171 G_B: 0.252 cycle_B: 1.140 idt_B: 0.046 \n",
            "End of epoch 159 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000812 -> 0.0000792\n",
            "(epoch: 160, iters: 97, time: 0.332, data: 0.002) D_A: 0.285 G_A: 0.210 cycle_A: 0.240 idt_A: 0.344 D_B: 0.048 G_B: 0.531 cycle_B: 0.908 idt_B: 0.071 \n",
            "(epoch: 160, iters: 197, time: 0.332, data: 0.002) D_A: 0.566 G_A: 0.529 cycle_A: 0.781 idt_A: 0.354 D_B: 0.096 G_B: 0.364 cycle_B: 1.011 idt_B: 0.280 \n",
            "saving the model at the end of epoch 160, iters 34720\n",
            "End of epoch 160 / 200 \t Time Taken: 71 sec\n",
            "learning rate 0.0000792 -> 0.0000772\n",
            "(epoch: 161, iters: 80, time: 2.151, data: 0.001) D_A: 0.074 G_A: 0.329 cycle_A: 0.448 idt_A: 0.248 D_B: 0.136 G_B: 0.219 cycle_B: 0.887 idt_B: 0.148 \n",
            "(epoch: 161, iters: 180, time: 0.333, data: 0.002) D_A: 0.063 G_A: 0.633 cycle_A: 0.669 idt_A: 0.451 D_B: 0.115 G_B: 0.524 cycle_B: 1.146 idt_B: 0.220 \n",
            "End of epoch 161 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000772 -> 0.0000752\n",
            "(epoch: 162, iters: 63, time: 0.332, data: 0.002) D_A: 0.102 G_A: 0.113 cycle_A: 0.183 idt_A: 0.389 D_B: 0.140 G_B: 0.427 cycle_B: 1.203 idt_B: 0.062 \n",
            "saving the latest model (epoch 162, total_iters 35000)\n",
            "(epoch: 162, iters: 163, time: 0.332, data: 0.002) D_A: 0.380 G_A: 0.153 cycle_A: 0.376 idt_A: 0.347 D_B: 0.164 G_B: 0.373 cycle_B: 0.997 idt_B: 0.114 \n",
            "End of epoch 162 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000752 -> 0.0000733\n",
            "(epoch: 163, iters: 46, time: 2.070, data: 0.002) D_A: 0.226 G_A: 0.154 cycle_A: 0.485 idt_A: 0.336 D_B: 0.052 G_B: 0.690 cycle_B: 0.893 idt_B: 0.175 \n",
            "(epoch: 163, iters: 146, time: 0.333, data: 0.002) D_A: 0.109 G_A: 0.364 cycle_A: 0.470 idt_A: 0.460 D_B: 0.009 G_B: 1.102 cycle_B: 1.653 idt_B: 0.153 \n",
            "End of epoch 163 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0000733 -> 0.0000713\n",
            "(epoch: 164, iters: 29, time: 0.332, data: 0.001) D_A: 0.182 G_A: 0.237 cycle_A: 0.220 idt_A: 0.573 D_B: 0.007 G_B: 1.031 cycle_B: 1.589 idt_B: 0.068 \n",
            "(epoch: 164, iters: 129, time: 0.331, data: 0.002) D_A: 0.362 G_A: 0.132 cycle_A: 0.388 idt_A: 0.233 D_B: 0.020 G_B: 0.773 cycle_B: 0.791 idt_B: 0.118 \n",
            "End of epoch 164 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000713 -> 0.0000693\n",
            "(epoch: 165, iters: 12, time: 2.136, data: 0.002) D_A: 0.127 G_A: 0.556 cycle_A: 0.362 idt_A: 0.328 D_B: 0.007 G_B: 0.856 cycle_B: 1.048 idt_B: 0.110 \n",
            "(epoch: 165, iters: 112, time: 0.332, data: 0.002) D_A: 0.225 G_A: 0.238 cycle_A: 0.338 idt_A: 0.449 D_B: 0.009 G_B: 0.963 cycle_B: 1.100 idt_B: 0.121 \n",
            "(epoch: 165, iters: 212, time: 0.333, data: 0.002) D_A: 0.167 G_A: 0.264 cycle_A: 0.206 idt_A: 0.434 D_B: 0.006 G_B: 1.063 cycle_B: 1.205 idt_B: 0.061 \n",
            "saving the model at the end of epoch 165, iters 35805\n",
            "End of epoch 165 / 200 \t Time Taken: 73 sec\n",
            "learning rate 0.0000693 -> 0.0000673\n",
            "(epoch: 166, iters: 95, time: 0.332, data: 0.002) D_A: 0.200 G_A: 0.282 cycle_A: 0.308 idt_A: 0.330 D_B: 0.003 G_B: 0.982 cycle_B: 1.048 idt_B: 0.080 \n",
            "(epoch: 166, iters: 195, time: 2.059, data: 0.002) D_A: 0.173 G_A: 0.208 cycle_A: 0.767 idt_A: 0.396 D_B: 0.004 G_B: 0.940 cycle_B: 1.251 idt_B: 0.257 \n",
            "End of epoch 166 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000673 -> 0.0000653\n",
            "(epoch: 167, iters: 78, time: 0.332, data: 0.002) D_A: 0.236 G_A: 0.196 cycle_A: 0.344 idt_A: 0.270 D_B: 0.003 G_B: 0.900 cycle_B: 0.915 idt_B: 0.104 \n",
            "(epoch: 167, iters: 178, time: 0.332, data: 0.002) D_A: 0.137 G_A: 0.376 cycle_A: 0.187 idt_A: 0.221 D_B: 0.003 G_B: 1.077 cycle_B: 0.704 idt_B: 0.064 \n",
            "End of epoch 167 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000653 -> 0.0000634\n",
            "(epoch: 168, iters: 61, time: 0.332, data: 0.002) D_A: 0.205 G_A: 0.229 cycle_A: 0.477 idt_A: 0.305 D_B: 0.004 G_B: 0.917 cycle_B: 0.977 idt_B: 0.152 \n",
            "(epoch: 168, iters: 161, time: 2.162, data: 0.002) D_A: 0.225 G_A: 0.556 cycle_A: 0.195 idt_A: 0.218 D_B: 0.003 G_B: 0.928 cycle_B: 0.772 idt_B: 0.058 \n",
            "End of epoch 168 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000634 -> 0.0000614\n",
            "(epoch: 169, iters: 44, time: 0.332, data: 0.002) D_A: 0.382 G_A: 0.061 cycle_A: 0.159 idt_A: 0.423 D_B: 0.002 G_B: 0.919 cycle_B: 1.096 idt_B: 0.040 \n",
            "(epoch: 169, iters: 144, time: 0.332, data: 0.002) D_A: 0.183 G_A: 0.269 cycle_A: 0.204 idt_A: 0.309 D_B: 0.023 G_B: 1.212 cycle_B: 1.054 idt_B: 0.062 \n",
            "End of epoch 169 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000614 -> 0.0000594\n",
            "(epoch: 170, iters: 27, time: 0.332, data: 0.002) D_A: 0.125 G_A: 0.699 cycle_A: 0.746 idt_A: 0.272 D_B: 0.004 G_B: 0.991 cycle_B: 0.856 idt_B: 0.259 \n",
            "(epoch: 170, iters: 127, time: 2.106, data: 0.001) D_A: 0.271 G_A: 0.254 cycle_A: 0.231 idt_A: 0.466 D_B: 0.004 G_B: 0.945 cycle_B: 1.289 idt_B: 0.078 \n",
            "saving the model at the end of epoch 170, iters 36890\n",
            "End of epoch 170 / 200 \t Time Taken: 71 sec\n",
            "learning rate 0.0000594 -> 0.0000574\n",
            "(epoch: 171, iters: 10, time: 0.332, data: 0.002) D_A: 0.045 G_A: 0.414 cycle_A: 0.251 idt_A: 0.212 D_B: 0.004 G_B: 0.917 cycle_B: 0.657 idt_B: 0.084 \n",
            "(epoch: 171, iters: 110, time: 0.332, data: 0.002) D_A: 0.317 G_A: 0.250 cycle_A: 0.215 idt_A: 0.433 D_B: 0.093 G_B: 1.021 cycle_B: 1.202 idt_B: 0.073 \n",
            "(epoch: 171, iters: 210, time: 0.332, data: 0.001) D_A: 0.269 G_A: 0.354 cycle_A: 0.173 idt_A: 0.454 D_B: 0.008 G_B: 1.259 cycle_B: 1.179 idt_B: 0.048 \n",
            "End of epoch 171 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000574 -> 0.0000554\n",
            "(epoch: 172, iters: 93, time: 2.164, data: 0.001) D_A: 0.183 G_A: 0.260 cycle_A: 0.225 idt_A: 0.288 D_B: 0.004 G_B: 0.922 cycle_B: 0.970 idt_B: 0.062 \n",
            "(epoch: 172, iters: 193, time: 0.332, data: 0.002) D_A: 0.092 G_A: 0.202 cycle_A: 0.346 idt_A: 0.432 D_B: 0.020 G_B: 0.767 cycle_B: 1.205 idt_B: 0.115 \n",
            "End of epoch 172 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000554 -> 0.0000535\n",
            "(epoch: 173, iters: 76, time: 0.331, data: 0.002) D_A: 0.173 G_A: 0.265 cycle_A: 0.360 idt_A: 0.443 D_B: 0.003 G_B: 1.014 cycle_B: 1.263 idt_B: 0.110 \n",
            "(epoch: 173, iters: 176, time: 0.332, data: 0.002) D_A: 0.147 G_A: 0.298 cycle_A: 0.369 idt_A: 0.390 D_B: 0.003 G_B: 1.004 cycle_B: 1.115 idt_B: 0.113 \n",
            "End of epoch 173 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000535 -> 0.0000515\n",
            "(epoch: 174, iters: 59, time: 2.189, data: 0.002) D_A: 0.041 G_A: 0.298 cycle_A: 0.520 idt_A: 0.288 D_B: 0.003 G_B: 1.000 cycle_B: 0.882 idt_B: 0.177 \n",
            "(epoch: 174, iters: 159, time: 0.333, data: 0.002) D_A: 0.196 G_A: 0.386 cycle_A: 0.216 idt_A: 0.414 D_B: 0.002 G_B: 1.006 cycle_B: 1.183 idt_B: 0.054 \n",
            "End of epoch 174 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000515 -> 0.0000495\n",
            "(epoch: 175, iters: 42, time: 0.332, data: 0.002) D_A: 0.107 G_A: 0.448 cycle_A: 0.684 idt_A: 0.294 D_B: 0.003 G_B: 0.957 cycle_B: 0.871 idt_B: 0.238 \n",
            "(epoch: 175, iters: 142, time: 0.331, data: 0.002) D_A: 0.107 G_A: 0.433 cycle_A: 0.477 idt_A: 0.294 D_B: 0.004 G_B: 1.084 cycle_B: 0.871 idt_B: 0.173 \n",
            "saving the model at the end of epoch 175, iters 37975\n",
            "End of epoch 175 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0000495 -> 0.0000475\n",
            "(epoch: 176, iters: 25, time: 2.894, data: 0.002) D_A: 0.131 G_A: 0.266 cycle_A: 0.605 idt_A: 0.260 D_B: 0.003 G_B: 0.941 cycle_B: 0.854 idt_B: 0.194 \n",
            "(epoch: 176, iters: 125, time: 0.332, data: 0.002) D_A: 0.175 G_A: 0.253 cycle_A: 0.180 idt_A: 0.295 D_B: 0.002 G_B: 1.032 cycle_B: 0.941 idt_B: 0.057 \n",
            "End of epoch 176 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000475 -> 0.0000455\n",
            "(epoch: 177, iters: 8, time: 0.333, data: 0.002) D_A: 0.112 G_A: 0.287 cycle_A: 0.501 idt_A: 0.282 D_B: 0.453 G_B: 0.008 cycle_B: 0.898 idt_B: 0.144 \n",
            "(epoch: 177, iters: 108, time: 0.332, data: 0.002) D_A: 0.046 G_A: 0.369 cycle_A: 0.391 idt_A: 0.262 D_B: 0.195 G_B: 0.177 cycle_B: 0.925 idt_B: 0.105 \n",
            "(epoch: 177, iters: 208, time: 2.182, data: 0.001) D_A: 0.278 G_A: 0.175 cycle_A: 0.234 idt_A: 0.234 D_B: 0.177 G_B: 0.222 cycle_B: 0.766 idt_B: 0.076 \n",
            "End of epoch 177 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000455 -> 0.0000436\n",
            "(epoch: 178, iters: 91, time: 0.332, data: 0.002) D_A: 0.129 G_A: 0.255 cycle_A: 1.054 idt_A: 0.557 D_B: 0.115 G_B: 0.325 cycle_B: 1.414 idt_B: 0.382 \n",
            "(epoch: 178, iters: 191, time: 0.331, data: 0.002) D_A: 0.105 G_A: 0.494 cycle_A: 0.544 idt_A: 0.714 D_B: 0.160 G_B: 0.250 cycle_B: 1.475 idt_B: 0.176 \n",
            "End of epoch 178 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000436 -> 0.0000416\n",
            "(epoch: 179, iters: 74, time: 0.332, data: 0.002) D_A: 0.279 G_A: 0.319 cycle_A: 0.489 idt_A: 0.295 D_B: 0.224 G_B: 0.373 cycle_B: 1.043 idt_B: 0.144 \n",
            "(epoch: 179, iters: 174, time: 2.256, data: 0.002) D_A: 0.299 G_A: 0.231 cycle_A: 0.419 idt_A: 0.301 D_B: 0.145 G_B: 0.252 cycle_B: 1.089 idt_B: 0.151 \n",
            "End of epoch 179 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000416 -> 0.0000396\n",
            "(epoch: 180, iters: 57, time: 0.332, data: 0.002) D_A: 0.128 G_A: 0.352 cycle_A: 0.511 idt_A: 0.311 D_B: 0.105 G_B: 0.227 cycle_B: 0.751 idt_B: 0.150 \n",
            "(epoch: 180, iters: 157, time: 0.332, data: 0.002) D_A: 0.092 G_A: 0.485 cycle_A: 0.200 idt_A: 0.318 D_B: 0.142 G_B: 0.475 cycle_B: 1.033 idt_B: 0.049 \n",
            "saving the model at the end of epoch 180, iters 39060\n",
            "End of epoch 180 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0000396 -> 0.0000376\n",
            "(epoch: 181, iters: 40, time: 0.332, data: 0.002) D_A: 0.148 G_A: 0.245 cycle_A: 0.119 idt_A: 0.426 D_B: 0.351 G_B: 0.117 cycle_B: 1.198 idt_B: 0.046 \n",
            "(epoch: 181, iters: 140, time: 2.284, data: 0.002) D_A: 0.252 G_A: 0.259 cycle_A: 0.546 idt_A: 0.321 D_B: 0.195 G_B: 0.192 cycle_B: 1.131 idt_B: 0.151 \n",
            "End of epoch 181 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000376 -> 0.0000356\n",
            "(epoch: 182, iters: 23, time: 0.332, data: 0.001) D_A: 0.045 G_A: 0.553 cycle_A: 0.550 idt_A: 0.187 D_B: 0.166 G_B: 0.534 cycle_B: 0.539 idt_B: 0.166 \n",
            "(epoch: 182, iters: 123, time: 0.332, data: 0.002) D_A: 0.108 G_A: 0.434 cycle_A: 0.369 idt_A: 0.178 D_B: 0.152 G_B: 0.350 cycle_B: 0.539 idt_B: 0.116 \n",
            "End of epoch 182 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000356 -> 0.0000337\n",
            "(epoch: 183, iters: 6, time: 0.334, data: 0.001) D_A: 0.110 G_A: 0.208 cycle_A: 0.239 idt_A: 0.438 D_B: 0.047 G_B: 1.199 cycle_B: 1.458 idt_B: 0.061 \n",
            "(epoch: 183, iters: 106, time: 2.204, data: 0.000) D_A: 0.073 G_A: 0.274 cycle_A: 0.189 idt_A: 0.232 D_B: 0.008 G_B: 1.124 cycle_B: 0.736 idt_B: 0.065 \n",
            "(epoch: 183, iters: 206, time: 0.333, data: 0.002) D_A: 0.252 G_A: 0.453 cycle_A: 0.377 idt_A: 0.238 D_B: 0.014 G_B: 0.592 cycle_B: 0.872 idt_B: 0.113 \n",
            "End of epoch 183 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000337 -> 0.0000317\n",
            "(epoch: 184, iters: 89, time: 0.332, data: 0.002) D_A: 0.246 G_A: 0.614 cycle_A: 0.678 idt_A: 0.321 D_B: 0.011 G_B: 1.103 cycle_B: 0.842 idt_B: 0.188 \n",
            "(epoch: 184, iters: 189, time: 0.332, data: 0.002) D_A: 0.223 G_A: 0.274 cycle_A: 0.349 idt_A: 0.245 D_B: 0.008 G_B: 0.905 cycle_B: 0.733 idt_B: 0.106 \n",
            "End of epoch 184 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000317 -> 0.0000297\n",
            "(epoch: 185, iters: 72, time: 2.341, data: 0.002) D_A: 0.085 G_A: 0.570 cycle_A: 0.598 idt_A: 0.163 D_B: 0.008 G_B: 1.004 cycle_B: 0.508 idt_B: 0.215 \n",
            "saving the latest model (epoch 185, total_iters 40000)\n",
            "(epoch: 185, iters: 172, time: 0.332, data: 0.002) D_A: 0.104 G_A: 0.367 cycle_A: 0.386 idt_A: 0.281 D_B: 0.003 G_B: 0.941 cycle_B: 0.761 idt_B: 0.117 \n",
            "saving the model at the end of epoch 185, iters 40145\n",
            "End of epoch 185 / 200 \t Time Taken: 74 sec\n",
            "learning rate 0.0000297 -> 0.0000277\n",
            "(epoch: 186, iters: 55, time: 0.331, data: 0.002) D_A: 0.176 G_A: 0.290 cycle_A: 0.321 idt_A: 0.325 D_B: 0.006 G_B: 1.126 cycle_B: 1.064 idt_B: 0.103 \n",
            "(epoch: 186, iters: 155, time: 0.333, data: 0.002) D_A: 0.093 G_A: 0.303 cycle_A: 0.265 idt_A: 0.214 D_B: 0.004 G_B: 0.939 cycle_B: 0.641 idt_B: 0.083 \n",
            "End of epoch 186 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000277 -> 0.0000257\n",
            "(epoch: 187, iters: 38, time: 2.260, data: 0.002) D_A: 0.237 G_A: 0.303 cycle_A: 0.267 idt_A: 0.328 D_B: 0.014 G_B: 1.024 cycle_B: 0.951 idt_B: 0.067 \n",
            "(epoch: 187, iters: 138, time: 0.331, data: 0.002) D_A: 0.166 G_A: 0.477 cycle_A: 0.553 idt_A: 0.325 D_B: 0.181 G_B: 1.100 cycle_B: 1.093 idt_B: 0.185 \n",
            "End of epoch 187 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000257 -> 0.0000238\n",
            "(epoch: 188, iters: 21, time: 0.332, data: 0.002) D_A: 0.406 G_A: 0.307 cycle_A: 0.474 idt_A: 0.248 D_B: 0.008 G_B: 0.523 cycle_B: 0.893 idt_B: 0.169 \n",
            "(epoch: 188, iters: 121, time: 0.332, data: 0.002) D_A: 0.117 G_A: 0.382 cycle_A: 0.751 idt_A: 0.555 D_B: 0.167 G_B: 0.525 cycle_B: 1.489 idt_B: 0.269 \n",
            "End of epoch 188 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000238 -> 0.0000218\n",
            "(epoch: 189, iters: 4, time: 2.361, data: 0.002) D_A: 0.140 G_A: 0.167 cycle_A: 0.290 idt_A: 0.260 D_B: 0.271 G_B: 0.214 cycle_B: 0.837 idt_B: 0.092 \n",
            "(epoch: 189, iters: 104, time: 0.332, data: 0.003) D_A: 0.204 G_A: 0.337 cycle_A: 0.560 idt_A: 0.240 D_B: 0.080 G_B: 0.091 cycle_B: 0.810 idt_B: 0.170 \n",
            "(epoch: 189, iters: 204, time: 0.332, data: 0.002) D_A: 0.136 G_A: 0.356 cycle_A: 0.387 idt_A: 0.211 D_B: 0.082 G_B: 0.404 cycle_B: 0.668 idt_B: 0.138 \n",
            "End of epoch 189 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000218 -> 0.0000198\n",
            "(epoch: 190, iters: 87, time: 0.332, data: 0.002) D_A: 0.135 G_A: 0.416 cycle_A: 0.595 idt_A: 0.222 D_B: 0.152 G_B: 0.296 cycle_B: 0.710 idt_B: 0.200 \n",
            "(epoch: 190, iters: 187, time: 2.291, data: 0.002) D_A: 0.193 G_A: 0.362 cycle_A: 0.495 idt_A: 0.344 D_B: 0.154 G_B: 0.409 cycle_B: 1.017 idt_B: 0.148 \n",
            "saving the model at the end of epoch 190, iters 41230\n",
            "End of epoch 190 / 200 \t Time Taken: 73 sec\n",
            "learning rate 0.0000198 -> 0.0000178\n",
            "(epoch: 191, iters: 70, time: 0.332, data: 0.002) D_A: 0.249 G_A: 0.293 cycle_A: 0.398 idt_A: 0.341 D_B: 0.117 G_B: 0.411 cycle_B: 1.192 idt_B: 0.102 \n",
            "(epoch: 191, iters: 170, time: 0.332, data: 0.002) D_A: 0.166 G_A: 0.262 cycle_A: 0.188 idt_A: 0.210 D_B: 0.080 G_B: 0.525 cycle_B: 0.661 idt_B: 0.049 \n",
            "End of epoch 191 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000178 -> 0.0000158\n",
            "(epoch: 192, iters: 53, time: 0.332, data: 0.002) D_A: 0.224 G_A: 0.286 cycle_A: 0.338 idt_A: 0.281 D_B: 0.316 G_B: 0.268 cycle_B: 0.997 idt_B: 0.103 \n",
            "(epoch: 192, iters: 153, time: 2.363, data: 0.001) D_A: 0.105 G_A: 0.536 cycle_A: 0.512 idt_A: 0.296 D_B: 0.243 G_B: 0.344 cycle_B: 0.904 idt_B: 0.160 \n",
            "End of epoch 192 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000158 -> 0.0000139\n",
            "(epoch: 193, iters: 36, time: 0.332, data: 0.002) D_A: 0.055 G_A: 0.360 cycle_A: 0.299 idt_A: 0.266 D_B: 0.141 G_B: 0.423 cycle_B: 0.725 idt_B: 0.093 \n",
            "(epoch: 193, iters: 136, time: 0.331, data: 0.002) D_A: 0.278 G_A: 0.345 cycle_A: 0.298 idt_A: 0.227 D_B: 0.055 G_B: 0.150 cycle_B: 0.817 idt_B: 0.093 \n",
            "End of epoch 193 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000139 -> 0.0000119\n",
            "(epoch: 194, iters: 19, time: 0.331, data: 0.002) D_A: 0.233 G_A: 0.332 cycle_A: 0.453 idt_A: 0.202 D_B: 0.125 G_B: 0.287 cycle_B: 0.592 idt_B: 0.145 \n",
            "(epoch: 194, iters: 119, time: 2.333, data: 0.002) D_A: 0.163 G_A: 0.268 cycle_A: 0.238 idt_A: 0.417 D_B: 0.263 G_B: 0.388 cycle_B: 1.109 idt_B: 0.067 \n",
            "End of epoch 194 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000119 -> 0.0000099\n",
            "(epoch: 195, iters: 2, time: 0.333, data: 0.002) D_A: 0.254 G_A: 0.378 cycle_A: 0.477 idt_A: 0.299 D_B: 0.070 G_B: 0.157 cycle_B: 0.979 idt_B: 0.163 \n",
            "(epoch: 195, iters: 102, time: 0.331, data: 0.000) D_A: 0.206 G_A: 0.377 cycle_A: 0.694 idt_A: 0.435 D_B: 0.137 G_B: 0.481 cycle_B: 1.246 idt_B: 0.252 \n",
            "(epoch: 195, iters: 202, time: 0.332, data: 0.002) D_A: 0.123 G_A: 0.404 cycle_A: 0.421 idt_A: 0.226 D_B: 0.021 G_B: 0.305 cycle_B: 0.703 idt_B: 0.140 \n",
            "saving the model at the end of epoch 195, iters 42315\n",
            "End of epoch 195 / 200 \t Time Taken: 69 sec\n",
            "learning rate 0.0000099 -> 0.0000079\n",
            "(epoch: 196, iters: 85, time: 2.326, data: 0.002) D_A: 0.217 G_A: 0.336 cycle_A: 0.275 idt_A: 0.411 D_B: 0.195 G_B: 0.338 cycle_B: 1.101 idt_B: 0.073 \n",
            "(epoch: 196, iters: 185, time: 0.332, data: 0.002) D_A: 0.238 G_A: 0.300 cycle_A: 0.205 idt_A: 0.320 D_B: 0.095 G_B: 0.269 cycle_B: 0.785 idt_B: 0.058 \n",
            "End of epoch 196 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000079 -> 0.0000059\n",
            "(epoch: 197, iters: 68, time: 0.331, data: 0.002) D_A: 0.050 G_A: 0.393 cycle_A: 0.333 idt_A: 0.200 D_B: 0.046 G_B: 0.536 cycle_B: 0.570 idt_B: 0.103 \n",
            "(epoch: 197, iters: 168, time: 0.333, data: 0.002) D_A: 0.079 G_A: 0.261 cycle_A: 0.385 idt_A: 0.335 D_B: 0.248 G_B: 0.455 cycle_B: 1.008 idt_B: 0.115 \n",
            "End of epoch 197 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000059 -> 0.0000040\n",
            "(epoch: 198, iters: 51, time: 2.373, data: 0.002) D_A: 0.100 G_A: 0.421 cycle_A: 0.467 idt_A: 0.310 D_B: 0.138 G_B: 0.422 cycle_B: 0.960 idt_B: 0.151 \n",
            "(epoch: 198, iters: 151, time: 0.331, data: 0.002) D_A: 0.154 G_A: 0.335 cycle_A: 0.188 idt_A: 0.325 D_B: 0.295 G_B: 0.193 cycle_B: 1.069 idt_B: 0.057 \n",
            "End of epoch 198 / 200 \t Time Taken: 70 sec\n",
            "learning rate 0.0000040 -> 0.0000020\n",
            "(epoch: 199, iters: 34, time: 0.332, data: 0.002) D_A: 0.209 G_A: 0.373 cycle_A: 0.482 idt_A: 0.196 D_B: 0.159 G_B: 0.159 cycle_B: 0.658 idt_B: 0.157 \n",
            "(epoch: 199, iters: 134, time: 0.331, data: 0.001) D_A: 0.136 G_A: 0.362 cycle_A: 0.298 idt_A: 0.431 D_B: 0.209 G_B: 0.441 cycle_B: 1.155 idt_B: 0.090 \n",
            "End of epoch 199 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0000020 -> 0.0000000\n",
            "(epoch: 200, iters: 17, time: 2.456, data: 0.002) D_A: 0.153 G_A: 0.424 cycle_A: 0.459 idt_A: 0.258 D_B: 0.251 G_B: 0.391 cycle_B: 0.852 idt_B: 0.130 \n",
            "(epoch: 200, iters: 117, time: 0.332, data: 0.002) D_A: 0.099 G_A: 0.429 cycle_A: 0.350 idt_A: 0.201 D_B: 0.219 G_B: 0.298 cycle_B: 0.664 idt_B: 0.110 \n",
            "(epoch: 200, iters: 217, time: 0.332, data: 0.002) D_A: 0.121 G_A: 0.416 cycle_A: 0.244 idt_A: 0.197 D_B: 0.217 G_B: 0.343 cycle_B: 0.689 idt_B: 0.072 \n",
            "saving the model at the end of epoch 200, iters 43400\n",
            "End of epoch 200 / 200 \t Time Taken: 74 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UkcaFZiyASl"
      },
      "source": [
        "# Testing\n",
        "\n",
        "-   `python test.py --dataroot datasets/horse2zebra/testA --name horse2zebra_pretrained --model test --no_dropout`\n",
        "\n",
        "Change the `--dataroot` and `--name` to be consistent with your trained model's configuration.\n",
        "\n",
        "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
        "> The option --model test is used for generating results of CycleGAN only for one side. This option will automatically set --dataset_mode single, which only loads the images from one set. On the contrary, using --model cycle_gan requires loading and generating results in both directions, which is sometimes unnecessary. The results will be saved at ./results/. Use --results_dir {directory_path_to_save_result} to specify the results directory.\n",
        "\n",
        "> For your own experiments, you might want to specify --netG, --norm, --no_dropout to match the generator architecture of the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCsKkEq0yGh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b6d983-425e-43fb-e40d-4a17ec2be75b"
      },
      "source": [
        "!python test.py --dataroot sketch_impressionism/trainA --name /content/drive/MyDrive/0-Colab-Assets/train_cycleGAN --model test --no_dropout"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: sketch_impressionism/trainA   \t[default: None]\n",
            "             dataset_mode: single                        \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: test                          \n",
            "             model_suffix:                               \n",
            "               n_layers_D: 3                             \n",
            "                     name: /content/drive/MyDrive/0-Colab-Assets/train_cycleGAN\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \t[default: False]\n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [SingleDataset] was created\n",
            "initialize network with normal\n",
            "model [TestModel] was created\n",
            "loading the model from /content/drive/MyDrive/0-Colab-Assets/train_cycleGAN/latest_net_G.pth\n",
            "Traceback (most recent call last):\n",
            "  File \"test.py\", line 47, in <module>\n",
            "    model.setup(opt)               # regular setup: load and print networks; create schedulers\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/models/base_model.py\", line 88, in setup\n",
            "    self.load_networks(load_suffix)\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/models/base_model.py\", line 192, in load_networks\n",
            "    state_dict = torch.load(load_path, map_location=str(self.device))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 581, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 211, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/0-Colab-Assets/train_cycleGAN/latest_net_G.pth'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}